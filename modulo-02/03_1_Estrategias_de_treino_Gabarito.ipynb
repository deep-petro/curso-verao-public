{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "03_1_Estrategias_de_treino_Gabarito.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "5Xu4l1od4y1N",
        "rsOgJBcofpZN"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "63a6b5d2130f49de995d8b87298f393e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1267a539a61f48b499984017b344826b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e9c52220ba4348fcb03ad3d4c37224be",
              "IPY_MODEL_0f547a258bf4479d8566740d224b482a"
            ]
          }
        },
        "1267a539a61f48b499984017b344826b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e9c52220ba4348fcb03ad3d4c37224be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_157f152f56bb4275ad7417b60248c26e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5b3c87a00bf146f19a4840d708fc0b9d"
          }
        },
        "0f547a258bf4479d8566740d224b482a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a652e14b414541af88d691ef255feead",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170500096/? [00:20&lt;00:00, 52369918.15it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_647ddf9477db401fa19771363e3d95c0"
          }
        },
        "157f152f56bb4275ad7417b60248c26e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5b3c87a00bf146f19a4840d708fc0b9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a652e14b414541af88d691ef255feead": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "647ddf9477db401fa19771363e3d95c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9c4a1ea66ed340d8b0419cfd1b68b07c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5c40fb6eabfc42fa94455f62312251bd",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_501a5e66387e4c8fa7c51c35a2a591b4",
              "IPY_MODEL_70ef5ebd7daf4ccd8a419e8aba4e3f52"
            ]
          }
        },
        "5c40fb6eabfc42fa94455f62312251bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "501a5e66387e4c8fa7c51c35a2a591b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1e9b184b374d40958d822f6556ab4278",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d460f93e9ab14a8db6da01b38fbaffb5"
          }
        },
        "70ef5ebd7daf4ccd8a419e8aba4e3f52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_13b9ca5b94f44bb19bc934eb6bece083",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170500096/? [00:20&lt;00:00, 101312684.17it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c67ab45ebd4940d289eebf389c8441d0"
          }
        },
        "1e9b184b374d40958d822f6556ab4278": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d460f93e9ab14a8db6da01b38fbaffb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "13b9ca5b94f44bb19bc934eb6bece083": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c67ab45ebd4940d289eebf389c8441d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6a86388425dc489599970c9b3801eee0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8abf68df05c14455a2897d586062f8c0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_07bd158db3404238b6d9bf62d1e9d97a",
              "IPY_MODEL_1b8a79154b2941658881cd01d845ee3a"
            ]
          }
        },
        "8abf68df05c14455a2897d586062f8c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "07bd158db3404238b6d9bf62d1e9d97a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_93624a151d5b417a94913917dab7a4a2",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 241530880,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 241530880,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_152837ed260446efae63ef8740005fcf"
          }
        },
        "1b8a79154b2941658881cd01d845ee3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_706db527ad9e4887b3abc5734251bf27",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 230M/230M [4:53:46&lt;00:00, 13.7kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1bfd59c3cdcb4537befb43dabec38170"
          }
        },
        "93624a151d5b417a94913917dab7a4a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "152837ed260446efae63ef8740005fcf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "706db527ad9e4887b3abc5734251bf27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1bfd59c3cdcb4537befb43dabec38170": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7db3c0ff43e04691952117629c35e27a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0f61e529ad744770a3dab4b9559bce7a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8a4c99f60dcb4fad9f2ddc74b276cb3f",
              "IPY_MODEL_dfd1e09c66164db1b1ef047e511a6664"
            ]
          }
        },
        "0f61e529ad744770a3dab4b9559bce7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8a4c99f60dcb4fad9f2ddc74b276cb3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f015fdd0ec26420d818ca6721958065d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c9ad2879cd854026845449dfae56f8ff"
          }
        },
        "dfd1e09c66164db1b1ef047e511a6664": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_91b2b30a59f1407da07a5861ff744a5d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170500096/? [00:06&lt;00:00, 28337920.13it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1e4a98893bf04e0ebbd9527ce9700acd"
          }
        },
        "f015fdd0ec26420d818ca6721958065d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c9ad2879cd854026845449dfae56f8ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "91b2b30a59f1407da07a5861ff744a5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1e4a98893bf04e0ebbd9527ce9700acd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXlS74cg4Ebl"
      },
      "source": [
        "# Estratégias de treino\n",
        "\n",
        "Até agora no curso, vimos somente uma estratégia de treino para redes neurais: o treinamento do zero.\n",
        "Entretanto, há outras formas de se explorar redes neurais.\n",
        "Nessa aula, vamos rever a estratégia treinamento do zero além de apresentar duas novas formas:\n",
        "\n",
        "1.   rede neural como um extrator de características, e\n",
        "2.   *fine-tuning*.\n",
        "\n",
        "Para cada uma dessas estratégias, vamos apresentar sua definição, vantagens e desvantagens.\n",
        "Antes, vamos instalar o Pytorch, importar alguns pacotes e definir funções para carregar os dados.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDFChpaZ4MiW",
        "outputId": "92661a73-adbe-4a28-d184-4f46d933781a"
      },
      "source": [
        "import time, os, sys, numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch import optim\n",
        "from torchsummary import summary\n",
        "\n",
        "\n",
        "import time, os, sys, numpy as np\n",
        "\n",
        "# Test if GPU is avaliable, if not, use cpu instead\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "n = torch.cuda.device_count()\n",
        "devices_ids= list(range(n))\n",
        "print(device)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uF4QkjwG4RQI"
      },
      "source": [
        "def load_data_cifar10(batch_size, resize=None, root=os.path.join(\n",
        "        '~', '.pytorch', 'datasets', 'fashion-mnist')):\n",
        "    \"\"\"Download the Cifar10-MNIST dataset and then load into memory.\"\"\"\n",
        "    root = os.path.expanduser(root)\n",
        "    transformer = []\n",
        "    if resize:\n",
        "        transformer += [torchvision.transforms.Resize(resize)]\n",
        "    transformer += [torchvision.transforms.ToTensor()]\n",
        "    transformer = torchvision.transforms.Compose(transformer)\n",
        "\n",
        "    mnist_train = torchvision.datasets.CIFAR10(root=root, train=True,download=True,transform=transformer)\n",
        "    mnist_test = torchvision.datasets.CIFAR10(root=root, train=False,download=True,transform=transformer)\n",
        "    num_workers = 0 if sys.platform.startswith('win32') else 4\n",
        "\n",
        "\n",
        "\n",
        "    train_iter = torch.utils.data.DataLoader(mnist_train,\n",
        "                                  batch_size, shuffle=True,\n",
        "                                  num_workers=num_workers)\n",
        "    test_iter = torch.utils.data.DataLoader(mnist_test,\n",
        "                                 batch_size, shuffle=False,\n",
        "                                 num_workers=num_workers)\n",
        "    return train_iter, test_iter\n",
        "\n",
        "# funções básicas\n",
        "def _get_batch(batch):\n",
        "    \"\"\"Return features and labels on ctx.\"\"\"\n",
        "    features, labels = batch\n",
        "    if labels.type() != features.type():\n",
        "        labels = labels.type(features.type())\n",
        "    return (torch.nn.DataParallel(features, device_ids=devices_ids),\n",
        "            torch.nn.DataParallel(labels, device_ids=devices_ids), features.shape[0])\n",
        "\n",
        "# Função usada para calcular acurácia\n",
        "def evaluate_accuracy(data_iter, net, loss):\n",
        "    \"\"\"Evaluate accuracy of a model on the given data set.\"\"\"\n",
        "\n",
        "    acc_sum, n, l = torch.Tensor([0]), 0, 0\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "      for X, y in data_iter:\n",
        "          #y = y.astype('float32')\n",
        "          X, y = X.to(device), y.to(device)\n",
        "          y_hat = net(X)\n",
        "          l += loss(y_hat, y).sum()\n",
        "          acc_sum += (y_hat.argmax(axis=1) == y).sum().item()\n",
        "          n += y.size()[0]\n",
        "\n",
        "    return acc_sum.item() / n, l.item() / len(data_iter)\n",
        "  \n",
        "# Função usada no treinamento e validação da rede\n",
        "def train_validate(net, train_iter, test_iter, batch_size, trainer, loss,\n",
        "                   num_epochs):\n",
        "    print('training on', device)\n",
        "    for epoch in range(num_epochs):\n",
        "        net.train()\n",
        "        train_l_sum, train_acc_sum, n, start = 0.0, 0.0, 0, time.time()\n",
        "        for X, y in train_iter:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            y_hat = net(X)\n",
        "            trainer.zero_grad()\n",
        "            l = loss(y_hat, y).sum()\n",
        "            l.backward()\n",
        "            trainer.step()\n",
        "            train_l_sum += l.item()\n",
        "            train_acc_sum += (y_hat.argmax(axis=1) == y).sum().item()\n",
        "            n += y.size()[0]\n",
        "        test_acc, test_loss = evaluate_accuracy(test_iter, net, loss)\n",
        "        print('epoch %d, train loss %.4f, train acc %.3f, test loss %.4f, '\n",
        "              'test acc %.3f, time %.1f sec'\n",
        "              % (epoch + 1, train_l_sum / len(train_iter), train_acc_sum / n, test_loss, \n",
        "                 test_acc, time.time() - start))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Xu4l1od4y1N"
      },
      "source": [
        "## Treinamento do zero\n",
        "\n",
        "Como dito anteriormente, essa foi a única estratégia vista até o momento no curso.\n",
        "Nessa estratégia, uma rede neural é proposta, **inicializada com pesos aleatórios** e treinada até convergir.\n",
        "A **vantagem** dessa estratégia é liberdade para definir como quiser a arquitetura da rede e seus hiper-parâmetros\n",
        "Por outro lado, a **desvantagem** é que essa estratégia requer muitos dados para convergir a rede inicializada aleatoriamente.\n",
        "Logo, se tivermos poucos dados, essa não é a estratégia mais recomendada.\n",
        "Abaixo, uma representação visual dessa estratégia.\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img width=600 src=\"https://drive.google.com/uc?export=view&id=1_bBQjyoDqB3kQMncmVkuJwSxDs3rqUmM\">\n",
        "</p>\n",
        "\n",
        "Apesar de já termos visto essa estratégia na prática, vamos vê-la aqui novamente para efeitos de comparação com as outras técnicas. Para tal, vamos, primeiro, definimos a arquitetura da [AlexNet](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZAEDlZ-DgGd"
      },
      "source": [
        "class AlexNet(nn.Module):\n",
        "    def __init__(self, input_channels, classes=10, **kwargs):\n",
        "        super(AlexNet, self).__init__(**kwargs)\n",
        "        self.convs = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=input_channels, out_channels=96, kernel_size=11, stride=4, padding=0),   # entrada: (b, 3, 227, 227) e saida: (b, 96, 55, 55)\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, padding=0),                                   # entrada: (b, 96, 55, 55) e saida: (b, 96, 27, 27)\n",
        "\n",
        "            nn.Conv2d(in_channels=96, out_channels=256, kernel_size=5, stride=1, padding=2),  # entrada: (b, 96, 27, 27) e saida: (b, 256, 27, 27)\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, padding=0),                                   # entrada: (b, 256, 27, 27) e saida: (b, 256, 13, 13)\n",
        "            nn.Conv2d(in_channels=256, out_channels=384, kernel_size=3, stride=1, padding=1), # entrada: (b, 256, 13, 13) e saida: (b, 384, 13, 13)\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=384, out_channels=384, kernel_size=3, stride=1, padding=1), # entrada: (b, 384, 13, 13) e saida: (b, 384, 13, 13)\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, stride=1, padding=1), # entrada: (b, 384, 13, 13) e saida: (b, 256, 13, 13)\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, padding=0)                                    # entrada: (b, 256, 13, 13) e saida: (b, 256, 6, 6)\n",
        "        )\n",
        "\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Flatten(),                                                                     # entrada: (b, 256, 13, 13) e saida: (b, 256*6*6) = (b, 9216)\n",
        "            nn.Linear(9216, 4096),                                                             # entrada: (b, 9216) e saida: (b, 4096)\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(4096, 4096),                                                             # entrada: (b, 4096) e saida: (b, 4096)\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(4096, classes)                                                          # entrada: (b, 4096) e saida: (b, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.convs(x)\n",
        "        x = self.features(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "63a6b5d2130f49de995d8b87298f393e",
            "1267a539a61f48b499984017b344826b",
            "e9c52220ba4348fcb03ad3d4c37224be",
            "0f547a258bf4479d8566740d224b482a",
            "157f152f56bb4275ad7417b60248c26e",
            "5b3c87a00bf146f19a4840d708fc0b9d",
            "a652e14b414541af88d691ef255feead",
            "647ddf9477db401fa19771363e3d95c0"
          ]
        },
        "id": "9Wr5rH-KMNZo",
        "outputId": "5b781524-ed97-460c-e42d-6d7a1ad06560"
      },
      "source": [
        "# parâmetros: número de epochs, learning rate (ou taxa de aprendizado), \n",
        "# tamanho do batch, e lambda do weight decay\n",
        "num_epochs, lr, batch_size, wd_lambda = 20, 0.01, 100, 0.0001\n",
        "\n",
        "\n",
        "# rede baseada na AlexNet-5 \n",
        "net = AlexNet(3, 10)\n",
        "\n",
        "# Sending model to device\n",
        "net.to(device)\n",
        "print(summary(net,(3, 227, 227))) # visualize number of parameters' net, output of each layer and total mega bytes necessary for forward pass\n",
        "                                # and stored weights. \n",
        "\n",
        "# função de custo (ou loss)\n",
        "loss = nn.CrossEntropyLoss()\n",
        "\n",
        "# carregamento do dado: mnist\n",
        "train_iter, test_iter = load_data_cifar10(batch_size, resize=227)\n",
        "\n",
        "# trainer do gluon\n",
        "trainer = optim.SGD(net.parameters(), lr=lr, weight_decay=wd_lambda, momentum=0.9)\n",
        "\n",
        "# treinamento e validação via Pytorch\n",
        "train_validate(net, train_iter, test_iter, batch_size, trainer, loss, \n",
        "                num_epochs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 96, 55, 55]          34,944\n",
            "              ReLU-2           [-1, 96, 55, 55]               0\n",
            "         MaxPool2d-3           [-1, 96, 27, 27]               0\n",
            "            Conv2d-4          [-1, 256, 27, 27]         614,656\n",
            "              ReLU-5          [-1, 256, 27, 27]               0\n",
            "         MaxPool2d-6          [-1, 256, 13, 13]               0\n",
            "            Conv2d-7          [-1, 384, 13, 13]         885,120\n",
            "              ReLU-8          [-1, 384, 13, 13]               0\n",
            "            Conv2d-9          [-1, 384, 13, 13]       1,327,488\n",
            "             ReLU-10          [-1, 384, 13, 13]               0\n",
            "           Conv2d-11          [-1, 256, 13, 13]         884,992\n",
            "             ReLU-12          [-1, 256, 13, 13]               0\n",
            "        MaxPool2d-13            [-1, 256, 6, 6]               0\n",
            "          Flatten-14                 [-1, 9216]               0\n",
            "           Linear-15                 [-1, 4096]      37,752,832\n",
            "             ReLU-16                 [-1, 4096]               0\n",
            "          Dropout-17                 [-1, 4096]               0\n",
            "           Linear-18                 [-1, 4096]      16,781,312\n",
            "             ReLU-19                 [-1, 4096]               0\n",
            "          Dropout-20                 [-1, 4096]               0\n",
            "           Linear-21                   [-1, 10]          40,970\n",
            "================================================================\n",
            "Total params: 58,322,314\n",
            "Trainable params: 58,322,314\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.59\n",
            "Forward/backward pass size (MB): 11.11\n",
            "Params size (MB): 222.48\n",
            "Estimated Total Size (MB): 234.18\n",
            "----------------------------------------------------------------\n",
            "None\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /root/.pytorch/datasets/fashion-mnist/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "63a6b5d2130f49de995d8b87298f393e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /root/.pytorch/datasets/fashion-mnist/cifar-10-python.tar.gz to /root/.pytorch/datasets/fashion-mnist\n",
            "Files already downloaded and verified\n",
            "training on cuda\n",
            "epoch 1, train loss 2.2015, train acc 0.161, test loss 1.9719, test acc 0.281, time 92.1 sec\n",
            "epoch 2, train loss 1.7785, train acc 0.339, test loss 1.5453, test acc 0.423, time 93.5 sec\n",
            "epoch 3, train loss 1.4151, train acc 0.483, test loss 1.2054, test acc 0.574, time 94.3 sec\n",
            "epoch 4, train loss 1.1467, train acc 0.591, test loss 0.9854, test acc 0.656, time 94.4 sec\n",
            "epoch 5, train loss 0.9382, train acc 0.671, test loss 0.8815, test acc 0.693, time 94.5 sec\n",
            "epoch 6, train loss 0.7706, train acc 0.734, test loss 0.7898, test acc 0.728, time 95.9 sec\n",
            "epoch 7, train loss 0.6444, train acc 0.777, test loss 0.6734, test acc 0.770, time 95.3 sec\n",
            "epoch 8, train loss 0.5413, train acc 0.812, test loss 0.6623, test acc 0.779, time 95.8 sec\n",
            "epoch 9, train loss 0.4430, train acc 0.846, test loss 0.6259, test acc 0.789, time 98.7 sec\n",
            "epoch 10, train loss 0.3558, train acc 0.876, test loss 0.6036, test acc 0.799, time 99.4 sec\n",
            "epoch 11, train loss 0.2787, train acc 0.903, test loss 0.6869, test acc 0.795, time 99.3 sec\n",
            "epoch 12, train loss 0.2203, train acc 0.923, test loss 0.6432, test acc 0.808, time 99.4 sec\n",
            "epoch 13, train loss 0.1925, train acc 0.934, test loss 0.7119, test acc 0.801, time 97.3 sec\n",
            "epoch 14, train loss 0.1473, train acc 0.950, test loss 0.7386, test acc 0.807, time 97.1 sec\n",
            "epoch 15, train loss 0.1273, train acc 0.957, test loss 0.8623, test acc 0.805, time 97.3 sec\n",
            "epoch 16, train loss 0.1147, train acc 0.961, test loss 0.7945, test acc 0.803, time 98.0 sec\n",
            "epoch 17, train loss 0.0930, train acc 0.969, test loss 0.8906, test acc 0.813, time 97.9 sec\n",
            "epoch 18, train loss 0.0865, train acc 0.971, test loss 0.8490, test acc 0.810, time 99.5 sec\n",
            "epoch 19, train loss 0.0689, train acc 0.977, test loss 0.9094, test acc 0.806, time 101.2 sec\n",
            "epoch 20, train loss 0.0683, train acc 0.977, test loss 0.8422, test acc 0.816, time 100.3 sec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgJwhj2SSGFB"
      },
      "source": [
        "É muito comum se usar redes já existentes para aprender características em novos dados.\n",
        "Por isso, muitos frameworks já deixam as arquiteturas mais famosas pré-implementadas para que possam ser usadas.\n",
        "\n",
        "No Pytorch, podemos importar uma rede [AlexNet](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf) usando o pacote [torchvision.models](https://pytorch.org/docs/stable/torchvision/models.html#torchvision-models) do Pytorch.\n",
        "Há várias arquiteturas pré-definidas nessa biblioteca, incluindo várias [DenseNets](https://arxiv.org/pdf/1608.06993.pdf) e [ResNets](https://arxiv.org/abs/1603.05027), [VGGs](https://arxiv.org/abs/1409.1556), [SqueezeNets](https://arxiv.org/abs/1602.07360), etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "9c4a1ea66ed340d8b0419cfd1b68b07c",
            "5c40fb6eabfc42fa94455f62312251bd",
            "501a5e66387e4c8fa7c51c35a2a591b4",
            "70ef5ebd7daf4ccd8a419e8aba4e3f52",
            "1e9b184b374d40958d822f6556ab4278",
            "d460f93e9ab14a8db6da01b38fbaffb5",
            "13b9ca5b94f44bb19bc934eb6bece083",
            "c67ab45ebd4940d289eebf389c8441d0"
          ]
        },
        "id": "f3u7xCEQM0qF",
        "outputId": "576b9bbe-98b0-4f5b-ce44-5ff4eae067fa"
      },
      "source": [
        "# parâmetros: número de epochs, learning rate (ou taxa de aprendizado), \n",
        "# tamanho do batch, e lambda do weight decay\n",
        "num_epochs, lr, batch_size, wd_lambda = 20, 0.01, 100, 0.0001\n",
        "\n",
        "# rede baseada na AlexNet-5 \n",
        "net = torchvision.models.alexnet(num_classes=10)\n",
        "\n",
        "# Sending model to device\n",
        "net.to(device)\n",
        "print(summary(net,(3,227,227))) # visualize number of parameters' net, output of each layer and total mega bytes necessary for forward pass\n",
        "                                # and stored weights. \n",
        "\n",
        "# função de custo (ou loss)\n",
        "loss = nn.CrossEntropyLoss()\n",
        "\n",
        "# carregamento do dado: mnist\n",
        "train_iter, test_iter = load_data_cifar10(batch_size, resize=227)\n",
        "\n",
        "# trainer do gluon\n",
        "trainer = optim.SGD(net.parameters(), lr=lr, weight_decay=wd_lambda, momentum=0.9)\n",
        "\n",
        "# treinamento e validação via Pytorch\n",
        "train_validate(net, train_iter, test_iter, batch_size, trainer, loss, \n",
        "                num_epochs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 56, 56]          23,296\n",
            "              ReLU-2           [-1, 64, 56, 56]               0\n",
            "         MaxPool2d-3           [-1, 64, 27, 27]               0\n",
            "            Conv2d-4          [-1, 192, 27, 27]         307,392\n",
            "              ReLU-5          [-1, 192, 27, 27]               0\n",
            "         MaxPool2d-6          [-1, 192, 13, 13]               0\n",
            "            Conv2d-7          [-1, 384, 13, 13]         663,936\n",
            "              ReLU-8          [-1, 384, 13, 13]               0\n",
            "            Conv2d-9          [-1, 256, 13, 13]         884,992\n",
            "             ReLU-10          [-1, 256, 13, 13]               0\n",
            "           Conv2d-11          [-1, 256, 13, 13]         590,080\n",
            "             ReLU-12          [-1, 256, 13, 13]               0\n",
            "        MaxPool2d-13            [-1, 256, 6, 6]               0\n",
            "AdaptiveAvgPool2d-14            [-1, 256, 6, 6]               0\n",
            "          Dropout-15                 [-1, 9216]               0\n",
            "           Linear-16                 [-1, 4096]      37,752,832\n",
            "             ReLU-17                 [-1, 4096]               0\n",
            "          Dropout-18                 [-1, 4096]               0\n",
            "           Linear-19                 [-1, 4096]      16,781,312\n",
            "             ReLU-20                 [-1, 4096]               0\n",
            "           Linear-21                   [-1, 10]          40,970\n",
            "================================================================\n",
            "Total params: 57,044,810\n",
            "Trainable params: 57,044,810\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.59\n",
            "Forward/backward pass size (MB): 8.48\n",
            "Params size (MB): 217.61\n",
            "Estimated Total Size (MB): 226.68\n",
            "----------------------------------------------------------------\n",
            "None\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /root/.pytorch/datasets/fashion-mnist/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9c4a1ea66ed340d8b0419cfd1b68b07c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /root/.pytorch/datasets/fashion-mnist/cifar-10-python.tar.gz to /root/.pytorch/datasets/fashion-mnist\n",
            "Files already downloaded and verified\n",
            "training on cuda\n",
            "epoch 1, train loss 2.2569, train acc 0.132, test loss 2.0560, test acc 0.233, time 87.3 sec\n",
            "epoch 2, train loss 1.8570, train acc 0.312, test loss 1.5836, test acc 0.414, time 87.2 sec\n",
            "epoch 3, train loss 1.4649, train acc 0.463, test loss 1.2912, test acc 0.530, time 88.2 sec\n",
            "epoch 4, train loss 1.2168, train acc 0.564, test loss 1.1152, test acc 0.600, time 88.2 sec\n",
            "epoch 5, train loss 0.9965, train acc 0.651, test loss 0.9834, test acc 0.658, time 88.5 sec\n",
            "epoch 6, train loss 0.8407, train acc 0.706, test loss 0.8171, test acc 0.722, time 88.8 sec\n",
            "epoch 7, train loss 0.7193, train acc 0.749, test loss 0.7321, test acc 0.749, time 88.4 sec\n",
            "epoch 8, train loss 0.6326, train acc 0.779, test loss 0.6461, test acc 0.778, time 88.1 sec\n",
            "epoch 9, train loss 0.5552, train acc 0.805, test loss 0.6047, test acc 0.793, time 88.2 sec\n",
            "epoch 10, train loss 0.4882, train acc 0.830, test loss 0.6147, test acc 0.788, time 88.2 sec\n",
            "epoch 11, train loss 0.4301, train acc 0.850, test loss 0.5401, test acc 0.815, time 88.5 sec\n",
            "epoch 12, train loss 0.3753, train acc 0.869, test loss 0.5618, test acc 0.809, time 88.5 sec\n",
            "epoch 13, train loss 0.3325, train acc 0.881, test loss 0.5655, test acc 0.813, time 88.2 sec\n",
            "epoch 14, train loss 0.2878, train acc 0.898, test loss 0.5629, test acc 0.827, time 88.6 sec\n",
            "epoch 15, train loss 0.2535, train acc 0.911, test loss 0.5592, test acc 0.825, time 88.7 sec\n",
            "epoch 16, train loss 0.2283, train acc 0.920, test loss 0.5841, test acc 0.827, time 88.7 sec\n",
            "epoch 17, train loss 0.2010, train acc 0.929, test loss 0.6103, test acc 0.816, time 88.4 sec\n",
            "epoch 18, train loss 0.1835, train acc 0.936, test loss 0.6266, test acc 0.816, time 88.6 sec\n",
            "epoch 19, train loss 0.1588, train acc 0.945, test loss 0.6158, test acc 0.826, time 88.6 sec\n",
            "epoch 20, train loss 0.1472, train acc 0.949, test loss 0.7042, test acc 0.814, time 88.0 sec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WyR3sukIS9D"
      },
      "source": [
        "## Extrator de características\n",
        "\n",
        "A terceira e última estratégia, mostrada na figura abaixo, é usar uma rede neural pré-treinada em algum dataset grande para extrair características de um outro dataset. Essa estratégia é preferível quando o dataset que se quer extrair as *features* tem muito poucas amostras, inviabilizando o treinamento ou *fine-tuning* da rede.\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img width=600 src=\"https://drive.google.com/uc?export=view&id=1pWGfQIAeOODIvm-IQ7De4kl60XpRYbb5\">\n",
        "</p>\n",
        "\n",
        "Existem duas formas de se explorar essa estratégia. A primeira consiste em substituir e treinar somente a última camada da rede neural. Nessa primeira forma, todas as outras camadas da rede ficam com *learning rate* 0, ou seja, não aprendem nada, e são somente usadas como codificadores/extratores de características. A segunda forma, *features* das imagens do dataset que se quer classificar são extraídas da penúltima camada da rede pré-treinada (geralmente, a camada antes da camada de classificação). Essas *features* são então usadas para se treinar um agoritmo externo (como um SVM ou *random forest*), que então classifica o dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VLBe7z2HmNK",
        "outputId": "ba0e5ad7-9991-4e19-dce3-71d816aa7e55"
      },
      "source": [
        "# rede baseada na AlexNet\n",
        "net = torchvision.models.alexnet(pretrained=True)\n",
        "\n",
        "# Sending model to device\n",
        "net.to(device)\n",
        "\n",
        "for param in net.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "print(summary(net, (3, 227, 227)))\n",
        "\n",
        "num_ftrs = net.classifier[6].in_features\n",
        "net.classifier[6] = nn.Linear(num_ftrs,10) # Alterando a última layer para retornar 10 classes ao invés de 1000\n",
        "\n",
        "# Sending model to device\n",
        "net.to(device)\n",
        "\n",
        "# Verifique no output a última camada do classifier, podemos ver que sua saída é 10\n",
        "print(net)\n",
        "\n",
        "# Podemos ver que este output mostra que apenas  40970 parâmetros serão treinados. Ou seja, somente a última camada\n",
        "print(summary(net, (3,227,227))) \n",
        "\n",
        "# Código retirado de https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html\n",
        "\n",
        "# Gather the parameters to be optimized/updated in this run. If we are\n",
        "#  finetuning we will be updating all parameters. However, if we are\n",
        "#  doing feature extract method, we will only update the parameters\n",
        "#  that we have just initialized, i.e. the parameters with requires_grad\n",
        "#  is True.\n",
        "print(\"Params to learn: \")\n",
        "\n",
        "params_to_update = []\n",
        "for name,param in net.named_parameters():\n",
        "    if param.requires_grad == True:\n",
        "        params_to_update.append(param)\n",
        "        print(\"\\t\",name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 56, 56]          23,296\n",
            "              ReLU-2           [-1, 64, 56, 56]               0\n",
            "         MaxPool2d-3           [-1, 64, 27, 27]               0\n",
            "            Conv2d-4          [-1, 192, 27, 27]         307,392\n",
            "              ReLU-5          [-1, 192, 27, 27]               0\n",
            "         MaxPool2d-6          [-1, 192, 13, 13]               0\n",
            "            Conv2d-7          [-1, 384, 13, 13]         663,936\n",
            "              ReLU-8          [-1, 384, 13, 13]               0\n",
            "            Conv2d-9          [-1, 256, 13, 13]         884,992\n",
            "             ReLU-10          [-1, 256, 13, 13]               0\n",
            "           Conv2d-11          [-1, 256, 13, 13]         590,080\n",
            "             ReLU-12          [-1, 256, 13, 13]               0\n",
            "        MaxPool2d-13            [-1, 256, 6, 6]               0\n",
            "AdaptiveAvgPool2d-14            [-1, 256, 6, 6]               0\n",
            "          Dropout-15                 [-1, 9216]               0\n",
            "           Linear-16                 [-1, 4096]      37,752,832\n",
            "             ReLU-17                 [-1, 4096]               0\n",
            "          Dropout-18                 [-1, 4096]               0\n",
            "           Linear-19                 [-1, 4096]      16,781,312\n",
            "             ReLU-20                 [-1, 4096]               0\n",
            "           Linear-21                 [-1, 1000]       4,097,000\n",
            "================================================================\n",
            "Total params: 61,100,840\n",
            "Trainable params: 0\n",
            "Non-trainable params: 61,100,840\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.59\n",
            "Forward/backward pass size (MB): 8.49\n",
            "Params size (MB): 233.08\n",
            "Estimated Total Size (MB): 242.16\n",
            "----------------------------------------------------------------\n",
            "None\n",
            "AlexNet(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): ReLU(inplace=True)\n",
            "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
            "  (classifier): Sequential(\n",
            "    (0): Dropout(p=0.5, inplace=False)\n",
            "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Dropout(p=0.5, inplace=False)\n",
            "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 56, 56]          23,296\n",
            "              ReLU-2           [-1, 64, 56, 56]               0\n",
            "         MaxPool2d-3           [-1, 64, 27, 27]               0\n",
            "            Conv2d-4          [-1, 192, 27, 27]         307,392\n",
            "              ReLU-5          [-1, 192, 27, 27]               0\n",
            "         MaxPool2d-6          [-1, 192, 13, 13]               0\n",
            "            Conv2d-7          [-1, 384, 13, 13]         663,936\n",
            "              ReLU-8          [-1, 384, 13, 13]               0\n",
            "            Conv2d-9          [-1, 256, 13, 13]         884,992\n",
            "             ReLU-10          [-1, 256, 13, 13]               0\n",
            "           Conv2d-11          [-1, 256, 13, 13]         590,080\n",
            "             ReLU-12          [-1, 256, 13, 13]               0\n",
            "        MaxPool2d-13            [-1, 256, 6, 6]               0\n",
            "AdaptiveAvgPool2d-14            [-1, 256, 6, 6]               0\n",
            "          Dropout-15                 [-1, 9216]               0\n",
            "           Linear-16                 [-1, 4096]      37,752,832\n",
            "             ReLU-17                 [-1, 4096]               0\n",
            "          Dropout-18                 [-1, 4096]               0\n",
            "           Linear-19                 [-1, 4096]      16,781,312\n",
            "             ReLU-20                 [-1, 4096]               0\n",
            "           Linear-21                   [-1, 10]          40,970\n",
            "================================================================\n",
            "Total params: 57,044,810\n",
            "Trainable params: 40,970\n",
            "Non-trainable params: 57,003,840\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.59\n",
            "Forward/backward pass size (MB): 8.48\n",
            "Params size (MB): 217.61\n",
            "Estimated Total Size (MB): 226.68\n",
            "----------------------------------------------------------------\n",
            "None\n",
            "Params to learn: \n",
            "\t classifier.6.weight\n",
            "\t classifier.6.bias\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fk0epQ2PDb0",
        "outputId": "7538a430-fc04-4b26-e1da-4de225349e42"
      },
      "source": [
        "# Treinando a última camada da rede acima\n",
        "# parâmetros: número de epochs, learning rate (ou taxa de aprendizado), \n",
        "# tamanho do batch, e lambda do weight decay\n",
        "num_epochs, lr, batch_size, wd_lambda = 20, 0.001, 100, 0.0001\n",
        "\n",
        "# função de custo (ou loss)\n",
        "loss = nn.CrossEntropyLoss()\n",
        "\n",
        "# carregamento do dado: mnist\n",
        "train_iter, test_iter = load_data_cifar10(batch_size, resize=227)\n",
        "\n",
        "# trainer do gluon\n",
        "trainer = optim.SGD(params_to_update, lr=lr, weight_decay=wd_lambda, momentum=0.9)\n",
        "\n",
        "# treinamento e validação via Pytorch\n",
        "train_validate(net, train_iter, test_iter, batch_size, trainer, loss, \n",
        "                num_epochs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "training on cuda\n",
            "epoch 1, train loss 1.3262, train acc 0.534, test loss 1.0916, test acc 0.610, time 86.6 sec\n",
            "epoch 2, train loss 1.1642, train acc 0.588, test loss 0.9961, test acc 0.654, time 86.8 sec\n",
            "epoch 3, train loss 1.1277, train acc 0.602, test loss 0.9634, test acc 0.662, time 86.9 sec\n",
            "epoch 4, train loss 1.1151, train acc 0.606, test loss 0.9462, test acc 0.672, time 86.8 sec\n",
            "epoch 5, train loss 1.0945, train acc 0.614, test loss 0.9265, test acc 0.676, time 86.7 sec\n",
            "epoch 6, train loss 1.0882, train acc 0.618, test loss 0.9345, test acc 0.671, time 86.8 sec\n",
            "epoch 7, train loss 1.0796, train acc 0.618, test loss 0.9326, test acc 0.678, time 86.5 sec\n",
            "epoch 8, train loss 1.0778, train acc 0.619, test loss 0.8997, test acc 0.684, time 86.5 sec\n",
            "epoch 9, train loss 1.0652, train acc 0.626, test loss 0.9065, test acc 0.679, time 86.6 sec\n",
            "epoch 10, train loss 1.0652, train acc 0.624, test loss 0.8911, test acc 0.687, time 86.8 sec\n",
            "epoch 11, train loss 1.0613, train acc 0.623, test loss 0.9190, test acc 0.674, time 87.0 sec\n",
            "epoch 12, train loss 1.0560, train acc 0.625, test loss 0.9070, test acc 0.678, time 86.6 sec\n",
            "epoch 13, train loss 1.0552, train acc 0.627, test loss 0.8888, test acc 0.686, time 86.7 sec\n",
            "epoch 14, train loss 1.0525, train acc 0.627, test loss 0.9140, test acc 0.673, time 86.8 sec\n",
            "epoch 15, train loss 1.0493, train acc 0.628, test loss 0.8974, test acc 0.684, time 86.7 sec\n",
            "epoch 16, train loss 1.0452, train acc 0.632, test loss 0.9008, test acc 0.683, time 86.6 sec\n",
            "epoch 17, train loss 1.0462, train acc 0.631, test loss 0.8753, test acc 0.693, time 86.6 sec\n",
            "epoch 18, train loss 1.0478, train acc 0.630, test loss 0.8919, test acc 0.681, time 86.8 sec\n",
            "epoch 19, train loss 1.0452, train acc 0.630, test loss 0.9101, test acc 0.679, time 86.5 sec\n",
            "epoch 20, train loss 1.0377, train acc 0.634, test loss 0.8619, test acc 0.698, time 86.9 sec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozt5EPQmSsx1",
        "outputId": "82b0c52f-afb0-4324-f260-d832917ac1b5"
      },
      "source": [
        "# parâmetros: número de epochs, learning rate (ou taxa de aprendizado), \n",
        "# tamanho do batch, e lambda do weight decay\n",
        "num_epochs, lr, batch_size, wd_lambda = 20, 0.01, 100, 0.0001\n",
        "\n",
        "# rede baseada na AlexNet-5 \n",
        "net = torchvision.models.alexnet(pretrained=True)\n",
        "\n",
        "# Sending model to device\n",
        "net.to(device)\n",
        "\n",
        "# carregamento do dado: fashion mnist\n",
        "train_iter, test_iter = load_data_cifar10(batch_size, resize=227)  \n",
        "\n",
        "# remove last fully-connected layer\n",
        "new_classifier = nn.Sequential(*list(net.classifier.children())[:-1])\n",
        "net.classifier = new_classifier\n",
        "\n",
        "print(summary(net,(3,227,227))) # visualize number of parameters' net, output of each layer and total mega bytes necessary for forward pass\n",
        "                                # and stored weights. \n",
        "\n",
        "first = True    \n",
        "with torch.no_grad():\n",
        "    for X, y in train_iter:\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        features = net(X)\n",
        "        if first is True:\n",
        "          train_features = features.cpu().numpy()\n",
        "          train_labels = y.cpu().numpy()\n",
        "          first = False\n",
        "        else:\n",
        "          train_features = np.concatenate((train_features, features.cpu().numpy()))\n",
        "          train_labels = np.concatenate((train_labels, y.cpu().numpy()))\n",
        "\n",
        "\n",
        "first = True    \n",
        "with torch.no_grad():\n",
        "    for X, y in test_iter:\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        features = net(X)\n",
        "        if first is True:\n",
        "          test_features = features.cpu().numpy()\n",
        "          test_labels = y.cpu().numpy()\n",
        "          first = False\n",
        "        else:\n",
        "          test_features = np.concatenate((test_features, features.cpu().numpy()))\n",
        "          test_labels = np.concatenate((test_labels, y.cpu().numpy()))\n",
        "\n",
        "          \n",
        "print(train_features.shape, test_features.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 56, 56]          23,296\n",
            "              ReLU-2           [-1, 64, 56, 56]               0\n",
            "         MaxPool2d-3           [-1, 64, 27, 27]               0\n",
            "            Conv2d-4          [-1, 192, 27, 27]         307,392\n",
            "              ReLU-5          [-1, 192, 27, 27]               0\n",
            "         MaxPool2d-6          [-1, 192, 13, 13]               0\n",
            "            Conv2d-7          [-1, 384, 13, 13]         663,936\n",
            "              ReLU-8          [-1, 384, 13, 13]               0\n",
            "            Conv2d-9          [-1, 256, 13, 13]         884,992\n",
            "             ReLU-10          [-1, 256, 13, 13]               0\n",
            "           Conv2d-11          [-1, 256, 13, 13]         590,080\n",
            "             ReLU-12          [-1, 256, 13, 13]               0\n",
            "        MaxPool2d-13            [-1, 256, 6, 6]               0\n",
            "AdaptiveAvgPool2d-14            [-1, 256, 6, 6]               0\n",
            "          Dropout-15                 [-1, 9216]               0\n",
            "           Linear-16                 [-1, 4096]      37,752,832\n",
            "             ReLU-17                 [-1, 4096]               0\n",
            "          Dropout-18                 [-1, 4096]               0\n",
            "           Linear-19                 [-1, 4096]      16,781,312\n",
            "             ReLU-20                 [-1, 4096]               0\n",
            "================================================================\n",
            "Total params: 57,003,840\n",
            "Trainable params: 57,003,840\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.59\n",
            "Forward/backward pass size (MB): 8.48\n",
            "Params size (MB): 217.45\n",
            "Estimated Total Size (MB): 226.52\n",
            "----------------------------------------------------------------\n",
            "None\n",
            "(50000, 4096) (10000, 4096)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BR7LqiOTY6Tc",
        "outputId": "76c66d61-8dab-46cd-cfd3-58152fc3324a"
      },
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "clf = LinearSVC()\n",
        "clf.fit(train_features, train_labels)\n",
        "\n",
        "pred = clf.predict(test_features)\n",
        "print(accuracy_score(test_labels, pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.5193\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsOgJBcofpZN"
      },
      "source": [
        "## *Fine-tuning*\n",
        "\n",
        "A segunda estratégia é chamada de *fine-tuning*, e é comumente classificada como um estratégia de *transfer learning*, onde o aprendizado é transferido entre datasets.\n",
        "Especificamente, esta estratégia, representada na figura abaixo, tenta usar um modelo pré-treinado aprendido anteriormente em algum dataset (geralmente muito grande, como o [ImageNet](http://www.image-net.org/)) para classificar outro conjunto de dados diferentes (geralmente com poucas amostras).\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img width=600 src=\"https://drive.google.com/uc?export=view&id=1CoOfpMcQAEl9YAL0lgW11LLYpDcnL4dQ\">\n",
        "</p>\n",
        "\n",
        "Como esses dados podem possuir características diferentes, treinamos a rede usando um *learning rate* pequeno, apenas para fazer pequenos ajustes nos pesos. Entretanto, como esses datasets geralmente tem número e classes diferentes, a última camada não é usada nessa transferência de peso e, geralmente, é inicializada aleatoriamente (e por isso, tem um *learning rate* mais alto que as demais camadas).\n",
        "\n",
        "Por fim, é um [fato conhecido](https://arxiv.org/pdf/1602.01517.pdf) que as redes neurais conseguem aprender características de baixo nível nas camadas iniciais. Geralmente, essas características são comuns à vários datasets. Por isso, uma opção durante o processo de *fine-tuning* é \"congelar\" as camadas iniciais (ou seja, não treiná-las) e treinar somente as demais camadas com taxa de aprendizado bem pequeno (exceto pela camada de classificação).\n",
        "\n",
        "No bloco de código abaixo, importamos a rede pré-treinada [AlexNet](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf), que foi treinada no dataset do [ImageNet](http://www.image-net.org/), que tem 1000 classes. Como iremos fazer *fine-tuning* nessa arquitetura para o dataset do [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html), que tem somente 10 classes, removeremos a última camada e criaremos uma nova camada inicializada aleatoriamente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hDGgIDhdG2z",
        "outputId": "61777eec-bff0-4563-e931-f0e9a101b357"
      },
      "source": [
        "# rede baseada na AlexNet \n",
        "net = torchvision.models.alexnet(pretrained=True)\n",
        "\n",
        "# Sending model to device\n",
        "net.to(device)\n",
        "\n",
        "print(summary(net,(3,227,227))) # visualize number of parameters' net, output of each layer and total mega bytes necessary for forward pass\n",
        "                                # and stored weights. \n",
        "\n",
        "num_ftrs = net.classifier[6].in_features\n",
        "net.classifier[6] = nn.Linear(num_ftrs,10) # Alterando a última layer para retornar 10 classes ao invés de 1000\n",
        "\n",
        "# Sending model to device\n",
        "net.to(device)\n",
        "\n",
        "# Verifique no output a última camada do classifier, podemos ver que sua saída é 10\n",
        "print(net)\n",
        "\n",
        "# Podemos ver que este output mostra que apenas  40970 parâmetros serão treinados. Ou seja, somente a última camada\n",
        "print(summary(net,(3,227,227))) \n",
        "\n",
        "# Treinando a última camada da rede acima\n",
        "# parâmetros: número de epochs, learning rate (ou taxa de aprendizado), \n",
        "# tamanho do batch, e lambda do weight decay\n",
        "num_epochs, lr, batch_size, wd_lambda = 20, 0.001, 100, 0.0001\n",
        "\n",
        "\n",
        "# função de custo (ou loss)\n",
        "loss = nn.CrossEntropyLoss()\n",
        "\n",
        "# carregamento do dado: cifar 10\n",
        "train_iter, test_iter = load_data_cifar10(batch_size, resize=227)\n",
        "\n",
        "# trainer\n",
        "trainer = optim.SGD([\n",
        "                {'params': net.features.parameters(), 'lr': lr * 0.1},\n",
        "                {'params': net.classifier[0:6].parameters(), 'lr': lr * 0.1},\n",
        "                {'params': net.classifier[6].parameters(), 'lr': lr}], weight_decay=wd_lambda, momentum=0.9)\n",
        "\n",
        "# treinamento e validação via Pytorch\n",
        "train_validate(net, train_iter, test_iter, batch_size, trainer, loss, \n",
        "                num_epochs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 56, 56]          23,296\n",
            "              ReLU-2           [-1, 64, 56, 56]               0\n",
            "         MaxPool2d-3           [-1, 64, 27, 27]               0\n",
            "            Conv2d-4          [-1, 192, 27, 27]         307,392\n",
            "              ReLU-5          [-1, 192, 27, 27]               0\n",
            "         MaxPool2d-6          [-1, 192, 13, 13]               0\n",
            "            Conv2d-7          [-1, 384, 13, 13]         663,936\n",
            "              ReLU-8          [-1, 384, 13, 13]               0\n",
            "            Conv2d-9          [-1, 256, 13, 13]         884,992\n",
            "             ReLU-10          [-1, 256, 13, 13]               0\n",
            "           Conv2d-11          [-1, 256, 13, 13]         590,080\n",
            "             ReLU-12          [-1, 256, 13, 13]               0\n",
            "        MaxPool2d-13            [-1, 256, 6, 6]               0\n",
            "AdaptiveAvgPool2d-14            [-1, 256, 6, 6]               0\n",
            "          Dropout-15                 [-1, 9216]               0\n",
            "           Linear-16                 [-1, 4096]      37,752,832\n",
            "             ReLU-17                 [-1, 4096]               0\n",
            "          Dropout-18                 [-1, 4096]               0\n",
            "           Linear-19                 [-1, 4096]      16,781,312\n",
            "             ReLU-20                 [-1, 4096]               0\n",
            "           Linear-21                 [-1, 1000]       4,097,000\n",
            "================================================================\n",
            "Total params: 61,100,840\n",
            "Trainable params: 61,100,840\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.59\n",
            "Forward/backward pass size (MB): 8.49\n",
            "Params size (MB): 233.08\n",
            "Estimated Total Size (MB): 242.16\n",
            "----------------------------------------------------------------\n",
            "None\n",
            "AlexNet(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): ReLU(inplace=True)\n",
            "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
            "  (classifier): Sequential(\n",
            "    (0): Dropout(p=0.5, inplace=False)\n",
            "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Dropout(p=0.5, inplace=False)\n",
            "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 56, 56]          23,296\n",
            "              ReLU-2           [-1, 64, 56, 56]               0\n",
            "         MaxPool2d-3           [-1, 64, 27, 27]               0\n",
            "            Conv2d-4          [-1, 192, 27, 27]         307,392\n",
            "              ReLU-5          [-1, 192, 27, 27]               0\n",
            "         MaxPool2d-6          [-1, 192, 13, 13]               0\n",
            "            Conv2d-7          [-1, 384, 13, 13]         663,936\n",
            "              ReLU-8          [-1, 384, 13, 13]               0\n",
            "            Conv2d-9          [-1, 256, 13, 13]         884,992\n",
            "             ReLU-10          [-1, 256, 13, 13]               0\n",
            "           Conv2d-11          [-1, 256, 13, 13]         590,080\n",
            "             ReLU-12          [-1, 256, 13, 13]               0\n",
            "        MaxPool2d-13            [-1, 256, 6, 6]               0\n",
            "AdaptiveAvgPool2d-14            [-1, 256, 6, 6]               0\n",
            "          Dropout-15                 [-1, 9216]               0\n",
            "           Linear-16                 [-1, 4096]      37,752,832\n",
            "             ReLU-17                 [-1, 4096]               0\n",
            "          Dropout-18                 [-1, 4096]               0\n",
            "           Linear-19                 [-1, 4096]      16,781,312\n",
            "             ReLU-20                 [-1, 4096]               0\n",
            "           Linear-21                   [-1, 10]          40,970\n",
            "================================================================\n",
            "Total params: 57,044,810\n",
            "Trainable params: 57,044,810\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.59\n",
            "Forward/backward pass size (MB): 8.48\n",
            "Params size (MB): 217.61\n",
            "Estimated Total Size (MB): 226.68\n",
            "----------------------------------------------------------------\n",
            "None\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "training on cuda\n",
            "epoch 1, train loss 0.9806, train acc 0.654, test loss 0.6364, test acc 0.776, time 84.2 sec\n",
            "epoch 2, train loss 0.6690, train acc 0.768, test loss 0.5465, test acc 0.809, time 84.4 sec\n",
            "epoch 3, train loss 0.5880, train acc 0.794, test loss 0.5182, test acc 0.818, time 84.2 sec\n",
            "epoch 4, train loss 0.5356, train acc 0.815, test loss 0.4531, test acc 0.844, time 84.3 sec\n",
            "epoch 5, train loss 0.5001, train acc 0.827, test loss 0.4471, test acc 0.847, time 84.5 sec\n",
            "epoch 6, train loss 0.4728, train acc 0.834, test loss 0.4193, test acc 0.855, time 84.3 sec\n",
            "epoch 7, train loss 0.4471, train acc 0.845, test loss 0.3970, test acc 0.860, time 84.6 sec\n",
            "epoch 8, train loss 0.4314, train acc 0.849, test loss 0.4118, test acc 0.856, time 84.6 sec\n",
            "epoch 9, train loss 0.4126, train acc 0.854, test loss 0.3848, test acc 0.864, time 84.8 sec\n",
            "epoch 10, train loss 0.3979, train acc 0.861, test loss 0.3758, test acc 0.870, time 84.8 sec\n",
            "epoch 11, train loss 0.3882, train acc 0.864, test loss 0.3794, test acc 0.866, time 84.6 sec\n",
            "epoch 12, train loss 0.3738, train acc 0.868, test loss 0.3636, test acc 0.870, time 84.4 sec\n",
            "epoch 13, train loss 0.3635, train acc 0.873, test loss 0.3448, test acc 0.877, time 84.7 sec\n",
            "epoch 14, train loss 0.3552, train acc 0.876, test loss 0.3551, test acc 0.874, time 84.1 sec\n",
            "epoch 15, train loss 0.3435, train acc 0.879, test loss 0.3383, test acc 0.881, time 84.4 sec\n",
            "epoch 16, train loss 0.3370, train acc 0.882, test loss 0.3313, test acc 0.885, time 84.0 sec\n",
            "epoch 17, train loss 0.3267, train acc 0.887, test loss 0.3287, test acc 0.883, time 83.9 sec\n",
            "epoch 18, train loss 0.3179, train acc 0.890, test loss 0.3288, test acc 0.883, time 83.9 sec\n",
            "epoch 19, train loss 0.3146, train acc 0.891, test loss 0.3229, test acc 0.887, time 83.9 sec\n",
            "epoch 20, train loss 0.3056, train acc 0.893, test loss 0.3206, test acc 0.886, time 83.9 sec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_uFa_Msi-EP"
      },
      "source": [
        "## Prática\n",
        "\n",
        "1. É possível melhorar o resultado obtido anteriormente?\n",
        "Estude o [model_zoo](https://pytorch.org/docs/stable/torchvision/models.html)  e tente usar as estratégias anteriores com diferentes redes neurais para melhorar o resultado.\n",
        "Algumas redes possíveis:\n",
        "\n",
        "- [MobileNets](https://arxiv.org/abs/1801.04381)\n",
        "- [VGGs](https://arxiv.org/abs/1409.1556)\n",
        "- [ResNets](https://arxiv.org/abs/1603.05027)\n",
        "- [DenseNets](https://arxiv.org/pdf/1608.06993.pdf)\n",
        "\n",
        "2. Procure agora congelar algumas camadas para realizar o *fine-tuning*. Essa estratégia é melhor quando se tem poucas imagens para fazer o *fine-tuning*.\n",
        "\n",
        "3. Procura usar outros algoritmos de aprendizado de máquina (como [*random forest*](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) e [SVM-RBF](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)) para classificar *deep features* extraídas de uma rede neural pré-treinada.\n",
        "  1. Procure também extrair e classificar *features* de outras camadas convolucionais.\n",
        "\n",
        "4. Procure usar as diferentes estratégias para melhorar os resultados dos datasets que já usamos, como [MNIST](https://pytorch.org/docs/stable/torchvision/datasets.html#torchvision.datasets.MNIST) e [Fashion MNIST](https://pytorch.org/docs/stable/torchvision/datasets.html#torchvision.datasets.FashionMNIST)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVock9TsZaYO"
      },
      "source": [
        "### Fine-tuning ResNet-18"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUpWzBLYguiU",
        "outputId": "dfd01bb4-ca8d-4951-8123-5769a8e83a5b"
      },
      "source": [
        "# rede baseada na AlexNet \r\n",
        "net = torchvision.models.resnet18(pretrained=True)\r\n",
        "\r\n",
        "# Sending model to device\r\n",
        "net.to(device)\r\n",
        "\r\n",
        "print(net)\r\n",
        "\r\n",
        "num_ftrs = net.fc.in_features\r\n",
        "net.fc = nn.Linear(num_ftrs, 10) # Alterando a última layer para retornar 10 classes ao invés de 1000\r\n",
        "\r\n",
        "# Sending model to device\r\n",
        "net.to(device)\r\n",
        "\r\n",
        "# Verifique no output a última camada do classifier, podemos ver que sua saída é 10\r\n",
        "print(net)\r\n",
        "\r\n",
        "# Treinando a última camada da rede acima\r\n",
        "# parâmetros: número de epochs, learning rate (ou taxa de aprendizado), \r\n",
        "# tamanho do batch, e lambda do weight decay\r\n",
        "num_epochs, lr, batch_size, wd_lambda = 20, 0.001, 100, 0.0001\r\n",
        "\r\n",
        "# função de custo (ou loss)\r\n",
        "loss = nn.CrossEntropyLoss()\r\n",
        "\r\n",
        "# carregamento do dado: cifar 10\r\n",
        "train_iter, test_iter = load_data_cifar10(batch_size, resize=227)\r\n",
        "\r\n",
        "# trainer\r\n",
        "trainer = optim.SGD([\r\n",
        "                {'params': net.conv1.parameters(), 'lr': lr * 0.1},\r\n",
        "                {'params': net.bn1.parameters(), 'lr': lr * 0.1},\r\n",
        "                {'params': net.relu.parameters(), 'lr': lr * 0.1},\r\n",
        "                {'params': net.maxpool.parameters(), 'lr': lr * 0.1},\r\n",
        "                {'params': net.layer1.parameters(), 'lr': lr * 0.1},\r\n",
        "                {'params': net.layer2.parameters(), 'lr': lr * 0.1},\r\n",
        "                {'params': net.layer3.parameters(), 'lr': lr * 0.1},\r\n",
        "                {'params': net.layer4.parameters(), 'lr': lr * 0.1},\r\n",
        "                {'params': net.avgpool.parameters(), 'lr': lr * 0.1},\r\n",
        "                {'params': net.fc.parameters(), 'lr': lr}], weight_decay=wd_lambda, momentum=0.9)\r\n",
        "\r\n",
        "# treinamento e validação via Pytorch\r\n",
        "train_validate(net, train_iter, test_iter, batch_size, trainer, loss, \r\n",
        "                num_epochs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
            ")\n",
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "training on cuda\n",
            "epoch 1, train loss 0.9695, train acc 0.708, test loss 0.5114, test acc 0.840, time 194.4 sec\n",
            "epoch 2, train loss 0.4140, train acc 0.869, test loss 0.3553, test acc 0.883, time 194.7 sec\n",
            "epoch 3, train loss 0.3150, train acc 0.898, test loss 0.3018, test acc 0.900, time 194.6 sec\n",
            "epoch 4, train loss 0.2651, train acc 0.912, test loss 0.2781, test acc 0.906, time 194.7 sec\n",
            "epoch 5, train loss 0.2304, train acc 0.924, test loss 0.2516, test acc 0.915, time 194.6 sec\n",
            "epoch 6, train loss 0.2068, train acc 0.931, test loss 0.2454, test acc 0.915, time 194.6 sec\n",
            "epoch 7, train loss 0.1878, train acc 0.938, test loss 0.2264, test acc 0.922, time 194.6 sec\n",
            "epoch 8, train loss 0.1719, train acc 0.943, test loss 0.2159, test acc 0.927, time 194.7 sec\n",
            "epoch 9, train loss 0.1567, train acc 0.950, test loss 0.2128, test acc 0.926, time 194.6 sec\n",
            "epoch 10, train loss 0.1454, train acc 0.952, test loss 0.2140, test acc 0.927, time 194.8 sec\n",
            "epoch 11, train loss 0.1347, train acc 0.957, test loss 0.2023, test acc 0.930, time 194.5 sec\n",
            "epoch 12, train loss 0.1233, train acc 0.961, test loss 0.2021, test acc 0.931, time 194.5 sec\n",
            "epoch 13, train loss 0.1151, train acc 0.964, test loss 0.1976, test acc 0.934, time 194.6 sec\n",
            "epoch 14, train loss 0.1060, train acc 0.967, test loss 0.1964, test acc 0.932, time 194.5 sec\n",
            "epoch 15, train loss 0.0972, train acc 0.970, test loss 0.1974, test acc 0.932, time 194.4 sec\n",
            "epoch 16, train loss 0.0914, train acc 0.972, test loss 0.1963, test acc 0.932, time 194.5 sec\n",
            "epoch 17, train loss 0.0844, train acc 0.974, test loss 0.1933, test acc 0.934, time 194.2 sec\n",
            "epoch 18, train loss 0.0776, train acc 0.977, test loss 0.1942, test acc 0.934, time 194.6 sec\n",
            "epoch 19, train loss 0.0729, train acc 0.980, test loss 0.1912, test acc 0.936, time 194.4 sec\n",
            "epoch 20, train loss 0.0676, train acc 0.982, test loss 0.1952, test acc 0.934, time 194.6 sec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ru6oDk8ZgWO"
      },
      "source": [
        "### Extracting features ResNet-152"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "6a86388425dc489599970c9b3801eee0",
            "8abf68df05c14455a2897d586062f8c0",
            "07bd158db3404238b6d9bf62d1e9d97a",
            "1b8a79154b2941658881cd01d845ee3a",
            "93624a151d5b417a94913917dab7a4a2",
            "152837ed260446efae63ef8740005fcf",
            "706db527ad9e4887b3abc5734251bf27",
            "1bfd59c3cdcb4537befb43dabec38170",
            "7db3c0ff43e04691952117629c35e27a",
            "0f61e529ad744770a3dab4b9559bce7a",
            "8a4c99f60dcb4fad9f2ddc74b276cb3f",
            "dfd1e09c66164db1b1ef047e511a6664",
            "f015fdd0ec26420d818ca6721958065d",
            "c9ad2879cd854026845449dfae56f8ff",
            "91b2b30a59f1407da07a5861ff744a5d",
            "1e4a98893bf04e0ebbd9527ce9700acd"
          ]
        },
        "id": "651eAWJdKcuk",
        "outputId": "a5be8df5-70cc-48bc-f311-7d7d68a8ff22"
      },
      "source": [
        "# parâmetros: número de epochs, learning rate (ou taxa de aprendizado), \r\n",
        "# tamanho do batch, e lambda do weight decay\r\n",
        "num_epochs, lr, batch_size, wd_lambda = 20, 0.01, 100, 0.0001\r\n",
        "\r\n",
        "# rede baseada na resnet152\r\n",
        "net = torchvision.models.resnet152(pretrained=True)\r\n",
        "\r\n",
        "# Sending model to device\r\n",
        "net.to(device)\r\n",
        "\r\n",
        "# carregamento do dado: fashion mnist\r\n",
        "train_iter, test_iter = load_data_cifar10(batch_size, resize=227)  \r\n",
        "\r\n",
        "# remove last fully-connected layer\r\n",
        "modules=list(net.children())[:-1]\r\n",
        "net=nn.Sequential(*modules)\r\n",
        "\r\n",
        "print(summary(net,(3,227,227))) # visualize number of parameters' net, output of each layer and total mega bytes necessary for forward pass\r\n",
        "                                # and stored weights. \r\n",
        "\r\n",
        "first = True    \r\n",
        "with torch.no_grad():\r\n",
        "    for X, y in train_iter:\r\n",
        "        X, y = X.to(device), y.to(device)\r\n",
        "        features = net(X)\r\n",
        "        if first is True:\r\n",
        "          train_features = features.cpu().numpy()\r\n",
        "          train_labels = y.cpu().numpy()\r\n",
        "          first = False\r\n",
        "        else:\r\n",
        "          train_features = np.concatenate((train_features, features.cpu().numpy()))\r\n",
        "          train_labels = np.concatenate((train_labels, y.cpu().numpy()))\r\n",
        "\r\n",
        "\r\n",
        "first = True    \r\n",
        "with torch.no_grad():\r\n",
        "    for X, y in test_iter:\r\n",
        "        X, y = X.to(device), y.to(device)\r\n",
        "        features = net(X)\r\n",
        "        if first is True:\r\n",
        "          test_features = features.cpu().numpy()\r\n",
        "          test_labels = y.cpu().numpy()\r\n",
        "          first = False\r\n",
        "        else:\r\n",
        "          test_features = np.concatenate((test_features, features.cpu().numpy()))\r\n",
        "          test_labels = np.concatenate((test_labels, y.cpu().numpy()))\r\n",
        "\r\n",
        "          \r\n",
        "print(train_features.shape, test_features.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet152-b121ed2d.pth\" to /root/.cache/torch/hub/checkpoints/resnet152-b121ed2d.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6a86388425dc489599970c9b3801eee0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=241530880.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /root/.pytorch/datasets/fashion-mnist/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7db3c0ff43e04691952117629c35e27a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /root/.pytorch/datasets/fashion-mnist/cifar-10-python.tar.gz to /root/.pytorch/datasets/fashion-mnist\n",
            "Files already downloaded and verified\n",
            "\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 114, 114]           9,408\n",
            "       BatchNorm2d-2         [-1, 64, 114, 114]             128\n",
            "              ReLU-3         [-1, 64, 114, 114]               0\n",
            "         MaxPool2d-4           [-1, 64, 57, 57]               0\n",
            "            Conv2d-5           [-1, 64, 57, 57]           4,096\n",
            "       BatchNorm2d-6           [-1, 64, 57, 57]             128\n",
            "              ReLU-7           [-1, 64, 57, 57]               0\n",
            "            Conv2d-8           [-1, 64, 57, 57]          36,864\n",
            "       BatchNorm2d-9           [-1, 64, 57, 57]             128\n",
            "             ReLU-10           [-1, 64, 57, 57]               0\n",
            "           Conv2d-11          [-1, 256, 57, 57]          16,384\n",
            "      BatchNorm2d-12          [-1, 256, 57, 57]             512\n",
            "           Conv2d-13          [-1, 256, 57, 57]          16,384\n",
            "      BatchNorm2d-14          [-1, 256, 57, 57]             512\n",
            "             ReLU-15          [-1, 256, 57, 57]               0\n",
            "       Bottleneck-16          [-1, 256, 57, 57]               0\n",
            "           Conv2d-17           [-1, 64, 57, 57]          16,384\n",
            "      BatchNorm2d-18           [-1, 64, 57, 57]             128\n",
            "             ReLU-19           [-1, 64, 57, 57]               0\n",
            "           Conv2d-20           [-1, 64, 57, 57]          36,864\n",
            "      BatchNorm2d-21           [-1, 64, 57, 57]             128\n",
            "             ReLU-22           [-1, 64, 57, 57]               0\n",
            "           Conv2d-23          [-1, 256, 57, 57]          16,384\n",
            "      BatchNorm2d-24          [-1, 256, 57, 57]             512\n",
            "             ReLU-25          [-1, 256, 57, 57]               0\n",
            "       Bottleneck-26          [-1, 256, 57, 57]               0\n",
            "           Conv2d-27           [-1, 64, 57, 57]          16,384\n",
            "      BatchNorm2d-28           [-1, 64, 57, 57]             128\n",
            "             ReLU-29           [-1, 64, 57, 57]               0\n",
            "           Conv2d-30           [-1, 64, 57, 57]          36,864\n",
            "      BatchNorm2d-31           [-1, 64, 57, 57]             128\n",
            "             ReLU-32           [-1, 64, 57, 57]               0\n",
            "           Conv2d-33          [-1, 256, 57, 57]          16,384\n",
            "      BatchNorm2d-34          [-1, 256, 57, 57]             512\n",
            "             ReLU-35          [-1, 256, 57, 57]               0\n",
            "       Bottleneck-36          [-1, 256, 57, 57]               0\n",
            "           Conv2d-37          [-1, 128, 57, 57]          32,768\n",
            "      BatchNorm2d-38          [-1, 128, 57, 57]             256\n",
            "             ReLU-39          [-1, 128, 57, 57]               0\n",
            "           Conv2d-40          [-1, 128, 29, 29]         147,456\n",
            "      BatchNorm2d-41          [-1, 128, 29, 29]             256\n",
            "             ReLU-42          [-1, 128, 29, 29]               0\n",
            "           Conv2d-43          [-1, 512, 29, 29]          65,536\n",
            "      BatchNorm2d-44          [-1, 512, 29, 29]           1,024\n",
            "           Conv2d-45          [-1, 512, 29, 29]         131,072\n",
            "      BatchNorm2d-46          [-1, 512, 29, 29]           1,024\n",
            "             ReLU-47          [-1, 512, 29, 29]               0\n",
            "       Bottleneck-48          [-1, 512, 29, 29]               0\n",
            "           Conv2d-49          [-1, 128, 29, 29]          65,536\n",
            "      BatchNorm2d-50          [-1, 128, 29, 29]             256\n",
            "             ReLU-51          [-1, 128, 29, 29]               0\n",
            "           Conv2d-52          [-1, 128, 29, 29]         147,456\n",
            "      BatchNorm2d-53          [-1, 128, 29, 29]             256\n",
            "             ReLU-54          [-1, 128, 29, 29]               0\n",
            "           Conv2d-55          [-1, 512, 29, 29]          65,536\n",
            "      BatchNorm2d-56          [-1, 512, 29, 29]           1,024\n",
            "             ReLU-57          [-1, 512, 29, 29]               0\n",
            "       Bottleneck-58          [-1, 512, 29, 29]               0\n",
            "           Conv2d-59          [-1, 128, 29, 29]          65,536\n",
            "      BatchNorm2d-60          [-1, 128, 29, 29]             256\n",
            "             ReLU-61          [-1, 128, 29, 29]               0\n",
            "           Conv2d-62          [-1, 128, 29, 29]         147,456\n",
            "      BatchNorm2d-63          [-1, 128, 29, 29]             256\n",
            "             ReLU-64          [-1, 128, 29, 29]               0\n",
            "           Conv2d-65          [-1, 512, 29, 29]          65,536\n",
            "      BatchNorm2d-66          [-1, 512, 29, 29]           1,024\n",
            "             ReLU-67          [-1, 512, 29, 29]               0\n",
            "       Bottleneck-68          [-1, 512, 29, 29]               0\n",
            "           Conv2d-69          [-1, 128, 29, 29]          65,536\n",
            "      BatchNorm2d-70          [-1, 128, 29, 29]             256\n",
            "             ReLU-71          [-1, 128, 29, 29]               0\n",
            "           Conv2d-72          [-1, 128, 29, 29]         147,456\n",
            "      BatchNorm2d-73          [-1, 128, 29, 29]             256\n",
            "             ReLU-74          [-1, 128, 29, 29]               0\n",
            "           Conv2d-75          [-1, 512, 29, 29]          65,536\n",
            "      BatchNorm2d-76          [-1, 512, 29, 29]           1,024\n",
            "             ReLU-77          [-1, 512, 29, 29]               0\n",
            "       Bottleneck-78          [-1, 512, 29, 29]               0\n",
            "           Conv2d-79          [-1, 128, 29, 29]          65,536\n",
            "      BatchNorm2d-80          [-1, 128, 29, 29]             256\n",
            "             ReLU-81          [-1, 128, 29, 29]               0\n",
            "           Conv2d-82          [-1, 128, 29, 29]         147,456\n",
            "      BatchNorm2d-83          [-1, 128, 29, 29]             256\n",
            "             ReLU-84          [-1, 128, 29, 29]               0\n",
            "           Conv2d-85          [-1, 512, 29, 29]          65,536\n",
            "      BatchNorm2d-86          [-1, 512, 29, 29]           1,024\n",
            "             ReLU-87          [-1, 512, 29, 29]               0\n",
            "       Bottleneck-88          [-1, 512, 29, 29]               0\n",
            "           Conv2d-89          [-1, 128, 29, 29]          65,536\n",
            "      BatchNorm2d-90          [-1, 128, 29, 29]             256\n",
            "             ReLU-91          [-1, 128, 29, 29]               0\n",
            "           Conv2d-92          [-1, 128, 29, 29]         147,456\n",
            "      BatchNorm2d-93          [-1, 128, 29, 29]             256\n",
            "             ReLU-94          [-1, 128, 29, 29]               0\n",
            "           Conv2d-95          [-1, 512, 29, 29]          65,536\n",
            "      BatchNorm2d-96          [-1, 512, 29, 29]           1,024\n",
            "             ReLU-97          [-1, 512, 29, 29]               0\n",
            "       Bottleneck-98          [-1, 512, 29, 29]               0\n",
            "           Conv2d-99          [-1, 128, 29, 29]          65,536\n",
            "     BatchNorm2d-100          [-1, 128, 29, 29]             256\n",
            "            ReLU-101          [-1, 128, 29, 29]               0\n",
            "          Conv2d-102          [-1, 128, 29, 29]         147,456\n",
            "     BatchNorm2d-103          [-1, 128, 29, 29]             256\n",
            "            ReLU-104          [-1, 128, 29, 29]               0\n",
            "          Conv2d-105          [-1, 512, 29, 29]          65,536\n",
            "     BatchNorm2d-106          [-1, 512, 29, 29]           1,024\n",
            "            ReLU-107          [-1, 512, 29, 29]               0\n",
            "      Bottleneck-108          [-1, 512, 29, 29]               0\n",
            "          Conv2d-109          [-1, 128, 29, 29]          65,536\n",
            "     BatchNorm2d-110          [-1, 128, 29, 29]             256\n",
            "            ReLU-111          [-1, 128, 29, 29]               0\n",
            "          Conv2d-112          [-1, 128, 29, 29]         147,456\n",
            "     BatchNorm2d-113          [-1, 128, 29, 29]             256\n",
            "            ReLU-114          [-1, 128, 29, 29]               0\n",
            "          Conv2d-115          [-1, 512, 29, 29]          65,536\n",
            "     BatchNorm2d-116          [-1, 512, 29, 29]           1,024\n",
            "            ReLU-117          [-1, 512, 29, 29]               0\n",
            "      Bottleneck-118          [-1, 512, 29, 29]               0\n",
            "          Conv2d-119          [-1, 256, 29, 29]         131,072\n",
            "     BatchNorm2d-120          [-1, 256, 29, 29]             512\n",
            "            ReLU-121          [-1, 256, 29, 29]               0\n",
            "          Conv2d-122          [-1, 256, 15, 15]         589,824\n",
            "     BatchNorm2d-123          [-1, 256, 15, 15]             512\n",
            "            ReLU-124          [-1, 256, 15, 15]               0\n",
            "          Conv2d-125         [-1, 1024, 15, 15]         262,144\n",
            "     BatchNorm2d-126         [-1, 1024, 15, 15]           2,048\n",
            "          Conv2d-127         [-1, 1024, 15, 15]         524,288\n",
            "     BatchNorm2d-128         [-1, 1024, 15, 15]           2,048\n",
            "            ReLU-129         [-1, 1024, 15, 15]               0\n",
            "      Bottleneck-130         [-1, 1024, 15, 15]               0\n",
            "          Conv2d-131          [-1, 256, 15, 15]         262,144\n",
            "     BatchNorm2d-132          [-1, 256, 15, 15]             512\n",
            "            ReLU-133          [-1, 256, 15, 15]               0\n",
            "          Conv2d-134          [-1, 256, 15, 15]         589,824\n",
            "     BatchNorm2d-135          [-1, 256, 15, 15]             512\n",
            "            ReLU-136          [-1, 256, 15, 15]               0\n",
            "          Conv2d-137         [-1, 1024, 15, 15]         262,144\n",
            "     BatchNorm2d-138         [-1, 1024, 15, 15]           2,048\n",
            "            ReLU-139         [-1, 1024, 15, 15]               0\n",
            "      Bottleneck-140         [-1, 1024, 15, 15]               0\n",
            "          Conv2d-141          [-1, 256, 15, 15]         262,144\n",
            "     BatchNorm2d-142          [-1, 256, 15, 15]             512\n",
            "            ReLU-143          [-1, 256, 15, 15]               0\n",
            "          Conv2d-144          [-1, 256, 15, 15]         589,824\n",
            "     BatchNorm2d-145          [-1, 256, 15, 15]             512\n",
            "            ReLU-146          [-1, 256, 15, 15]               0\n",
            "          Conv2d-147         [-1, 1024, 15, 15]         262,144\n",
            "     BatchNorm2d-148         [-1, 1024, 15, 15]           2,048\n",
            "            ReLU-149         [-1, 1024, 15, 15]               0\n",
            "      Bottleneck-150         [-1, 1024, 15, 15]               0\n",
            "          Conv2d-151          [-1, 256, 15, 15]         262,144\n",
            "     BatchNorm2d-152          [-1, 256, 15, 15]             512\n",
            "            ReLU-153          [-1, 256, 15, 15]               0\n",
            "          Conv2d-154          [-1, 256, 15, 15]         589,824\n",
            "     BatchNorm2d-155          [-1, 256, 15, 15]             512\n",
            "            ReLU-156          [-1, 256, 15, 15]               0\n",
            "          Conv2d-157         [-1, 1024, 15, 15]         262,144\n",
            "     BatchNorm2d-158         [-1, 1024, 15, 15]           2,048\n",
            "            ReLU-159         [-1, 1024, 15, 15]               0\n",
            "      Bottleneck-160         [-1, 1024, 15, 15]               0\n",
            "          Conv2d-161          [-1, 256, 15, 15]         262,144\n",
            "     BatchNorm2d-162          [-1, 256, 15, 15]             512\n",
            "            ReLU-163          [-1, 256, 15, 15]               0\n",
            "          Conv2d-164          [-1, 256, 15, 15]         589,824\n",
            "     BatchNorm2d-165          [-1, 256, 15, 15]             512\n",
            "            ReLU-166          [-1, 256, 15, 15]               0\n",
            "          Conv2d-167         [-1, 1024, 15, 15]         262,144\n",
            "     BatchNorm2d-168         [-1, 1024, 15, 15]           2,048\n",
            "            ReLU-169         [-1, 1024, 15, 15]               0\n",
            "      Bottleneck-170         [-1, 1024, 15, 15]               0\n",
            "          Conv2d-171          [-1, 256, 15, 15]         262,144\n",
            "     BatchNorm2d-172          [-1, 256, 15, 15]             512\n",
            "            ReLU-173          [-1, 256, 15, 15]               0\n",
            "          Conv2d-174          [-1, 256, 15, 15]         589,824\n",
            "     BatchNorm2d-175          [-1, 256, 15, 15]             512\n",
            "            ReLU-176          [-1, 256, 15, 15]               0\n",
            "          Conv2d-177         [-1, 1024, 15, 15]         262,144\n",
            "     BatchNorm2d-178         [-1, 1024, 15, 15]           2,048\n",
            "            ReLU-179         [-1, 1024, 15, 15]               0\n",
            "      Bottleneck-180         [-1, 1024, 15, 15]               0\n",
            "          Conv2d-181          [-1, 256, 15, 15]         262,144\n",
            "     BatchNorm2d-182          [-1, 256, 15, 15]             512\n",
            "            ReLU-183          [-1, 256, 15, 15]               0\n",
            "          Conv2d-184          [-1, 256, 15, 15]         589,824\n",
            "     BatchNorm2d-185          [-1, 256, 15, 15]             512\n",
            "            ReLU-186          [-1, 256, 15, 15]               0\n",
            "          Conv2d-187         [-1, 1024, 15, 15]         262,144\n",
            "     BatchNorm2d-188         [-1, 1024, 15, 15]           2,048\n",
            "            ReLU-189         [-1, 1024, 15, 15]               0\n",
            "      Bottleneck-190         [-1, 1024, 15, 15]               0\n",
            "          Conv2d-191          [-1, 256, 15, 15]         262,144\n",
            "     BatchNorm2d-192          [-1, 256, 15, 15]             512\n",
            "            ReLU-193          [-1, 256, 15, 15]               0\n",
            "          Conv2d-194          [-1, 256, 15, 15]         589,824\n",
            "     BatchNorm2d-195          [-1, 256, 15, 15]             512\n",
            "            ReLU-196          [-1, 256, 15, 15]               0\n",
            "          Conv2d-197         [-1, 1024, 15, 15]         262,144\n",
            "     BatchNorm2d-198         [-1, 1024, 15, 15]           2,048\n",
            "            ReLU-199         [-1, 1024, 15, 15]               0\n",
            "      Bottleneck-200         [-1, 1024, 15, 15]               0\n",
            "          Conv2d-201          [-1, 256, 15, 15]         262,144\n",
            "     BatchNorm2d-202          [-1, 256, 15, 15]             512\n",
            "            ReLU-203          [-1, 256, 15, 15]               0\n",
            "          Conv2d-204          [-1, 256, 15, 15]         589,824\n",
            "     BatchNorm2d-205          [-1, 256, 15, 15]             512\n",
            "            ReLU-206          [-1, 256, 15, 15]               0\n",
            "          Conv2d-207         [-1, 1024, 15, 15]         262,144\n",
            "     BatchNorm2d-208         [-1, 1024, 15, 15]           2,048\n",
            "            ReLU-209         [-1, 1024, 15, 15]               0\n",
            "      Bottleneck-210         [-1, 1024, 15, 15]               0\n",
            "          Conv2d-211          [-1, 256, 15, 15]         262,144\n",
            "     BatchNorm2d-212          [-1, 256, 15, 15]             512\n",
            "            ReLU-213          [-1, 256, 15, 15]               0\n",
            "          Conv2d-214          [-1, 256, 15, 15]         589,824\n",
            "     BatchNorm2d-215          [-1, 256, 15, 15]             512\n",
            "            ReLU-216          [-1, 256, 15, 15]               0\n",
            "          Conv2d-217         [-1, 1024, 15, 15]         262,144\n",
            "     BatchNorm2d-218         [-1, 1024, 15, 15]           2,048\n",
            "            ReLU-219         [-1, 1024, 15, 15]               0\n",
            "      Bottleneck-220         [-1, 1024, 15, 15]               0\n",
            "          Conv2d-221          [-1, 256, 15, 15]         262,144\n",
            "     BatchNorm2d-222          [-1, 256, 15, 15]             512\n",
            "            ReLU-223          [-1, 256, 15, 15]               0\n",
            "          Conv2d-224          [-1, 256, 15, 15]         589,824\n",
            "     BatchNorm2d-225          [-1, 256, 15, 15]             512\n",
            "            ReLU-226          [-1, 256, 15, 15]               0\n",
            "          Conv2d-227         [-1, 1024, 15, 15]         262,144\n",
            "     BatchNorm2d-228         [-1, 1024, 15, 15]           2,048\n",
            "            ReLU-229         [-1, 1024, 15, 15]               0\n",
            "      Bottleneck-230         [-1, 1024, 15, 15]               0\n",
            "          Conv2d-231          [-1, 256, 15, 15]         262,144\n",
            "     BatchNorm2d-232          [-1, 256, 15, 15]             512\n",
            "            ReLU-233          [-1, 256, 15, 15]               0\n",
            "          Conv2d-234          [-1, 256, 15, 15]         589,824\n",
            "     BatchNorm2d-235          [-1, 256, 15, 15]             512\n",
            "            ReLU-236          [-1, 256, 15, 15]               0\n",
            "          Conv2d-237         [-1, 1024, 15, 15]         262,144\n",
            "     BatchNorm2d-238         [-1, 1024, 15, 15]           2,048\n",
            "            ReLU-239         [-1, 1024, 15, 15]               0\n",
            "      Bottleneck-240         [-1, 1024, 15, 15]               0\n",
            "          Conv2d-241          [-1, 256, 15, 15]         262,144\n",
            "     BatchNorm2d-242          [-1, 256, 15, 15]             512\n",
            "            ReLU-243          [-1, 256, 15, 15]               0\n",
            "          Conv2d-244          [-1, 256, 15, 15]         589,824\n",
            "     BatchNorm2d-245          [-1, 256, 15, 15]             512\n",
            "            ReLU-246          [-1, 256, 15, 15]               0\n",
            "          Conv2d-247         [-1, 1024, 15, 15]         262,144\n",
            "     BatchNorm2d-248         [-1, 1024, 15, 15]           2,048\n",
            "            ReLU-249         [-1, 1024, 15, 15]               0\n",
            "      Bottleneck-250         [-1, 1024, 15, 15]               0\n",
            "          Conv2d-251          [-1, 256, 15, 15]         262,144\n",
            "     BatchNorm2d-252          [-1, 256, 15, 15]             512\n",
            "            ReLU-253          [-1, 256, 15, 15]               0\n",
            "          Conv2d-254          [-1, 256, 15, 15]         589,824\n",
            "     BatchNorm2d-255          [-1, 256, 15, 15]             512\n",
            "            ReLU-256          [-1, 256, 15, 15]               0\n",
            "          Conv2d-257         [-1, 1024, 15, 15]         262,144\n",
            "     BatchNorm2d-258         [-1, 1024, 15, 15]           2,048\n",
            "            ReLU-259         [-1, 1024, 15, 15]               0\n",
            "      Bottleneck-260         [-1, 1024, 15, 15]               0\n",
            "          Conv2d-261          [-1, 256, 15, 15]         262,144\n",
            "     BatchNorm2d-262          [-1, 256, 15, 15]             512\n",
            "            ReLU-263          [-1, 256, 15, 15]               0\n",
            "          Conv2d-264          [-1, 256, 15, 15]         589,824\n",
            "     BatchNorm2d-265          [-1, 256, 15, 15]             512\n",
            "            ReLU-266          [-1, 256, 15, 15]               0\n",
            "          Conv2d-267         [-1, 1024, 15, 15]         262,144\n",
            "     BatchNorm2d-268         [-1, 1024, 15, 15]           2,048\n",
            "            ReLU-269         [-1, 1024, 15, 15]               0\n",
            "      Bottleneck-270         [-1, 1024, 15, 15]               0\n",
            "          Conv2d-271          [-1, 256, 15, 15]         262,144\n",
            "     BatchNorm2d-272          [-1, 256, 15, 15]             512\n",
            "            ReLU-273          [-1, 256, 15, 15]               0\n",
            "          Conv2d-274          [-1, 256, 15, 15]         589,824\n",
            "     BatchNorm2d-275          [-1, 256, 15, 15]             512\n",
            "            ReLU-276          [-1, 256, 15, 15]               0\n",
            "          Conv2d-277         [-1, 1024, 15, 15]         262,144\n",
            "     BatchNorm2d-278         [-1, 1024, 15, 15]           2,048\n",
            "            ReLU-279         [-1, 1024, 15, 15]               0\n",
            "      Bottleneck-280         [-1, 1024, 15, 15]               0\n",
            "          Conv2d-281          [-1, 256, 15, 15]         262,144\n",
            "     BatchNorm2d-282          [-1, 256, 15, 15]             512\n",
            "            ReLU-283          [-1, 256, 15, 15]               0\n",
            "          Conv2d-284          [-1, 256, 15, 15]         589,824\n",
            "     BatchNorm2d-285          [-1, 256, 15, 15]             512\n",
            "            ReLU-286          [-1, 256, 15, 15]               0\n",
            "          Conv2d-287         [-1, 1024, 15, 15]         262,144\n",
            "     BatchNorm2d-288         [-1, 1024, 15, 15]           2,048\n",
            "            ReLU-289         [-1, 1024, 15, 15]               0\n",
            "      Bottleneck-290         [-1, 1024, 15, 15]               0\n",
            "          Conv2d-291          [-1, 256, 15, 15]         262,144\n",
            "     BatchNorm2d-292          [-1, 256, 15, 15]             512\n",
            "            ReLU-293          [-1, 256, 15, 15]               0\n",
            "          Conv2d-294          [-1, 256, 15, 15]         589,824\n",
            "     BatchNorm2d-295          [-1, 256, 15, 15]             512\n",
            "            ReLU-296          [-1, 256, 15, 15]               0\n",
            "          Conv2d-297         [-1, 1024, 15, 15]         262,144\n",
            "     BatchNorm2d-298         [-1, 1024, 15, 15]           2,048\n",
            "            ReLU-299         [-1, 1024, 15, 15]               0\n",
            "      Bottleneck-300         [-1, 1024, 15, 15]               0\n",
            "          Conv2d-301          [-1, 256, 15, 15]         262,144\n",
            "     BatchNorm2d-302          [-1, 256, 15, 15]             512\n",
            "            ReLU-303          [-1, 256, 15, 15]               0\n",
            "          Conv2d-304          [-1, 256, 15, 15]         589,824\n",
            "     BatchNorm2d-305          [-1, 256, 15, 15]             512\n",
            "            ReLU-306          [-1, 256, 15, 15]               0\n",
            "          Conv2d-307         [-1, 1024, 15, 15]         262,144\n",
            "     BatchNorm2d-308         [-1, 1024, 15, 15]           2,048\n",
            "            ReLU-309         [-1, 1024, 15, 15]               0\n",
            "      Bottleneck-310         [-1, 1024, 15, 15]               0\n",
            "          Conv2d-311          [-1, 256, 15, 15]         262,144\n",
            "     BatchNorm2d-312          [-1, 256, 15, 15]             512\n",
            "            ReLU-313          [-1, 256, 15, 15]               0\n",
            "          Conv2d-314          [-1, 256, 15, 15]         589,824\n",
            "     BatchNorm2d-315          [-1, 256, 15, 15]             512\n",
            "            ReLU-316          [-1, 256, 15, 15]               0\n",
            "          Conv2d-317         [-1, 1024, 15, 15]         262,144\n",
            "     BatchNorm2d-318         [-1, 1024, 15, 15]           2,048\n",
            "            ReLU-319         [-1, 1024, 15, 15]               0\n",
            "      Bottleneck-320         [-1, 1024, 15, 15]               0\n",
            "          Conv2d-321          [-1, 256, 15, 15]         262,144\n",
            "     BatchNorm2d-322          [-1, 256, 15, 15]             512\n",
            "            ReLU-323          [-1, 256, 15, 15]               0\n",
            "          Conv2d-324          [-1, 256, 15, 15]         589,824\n",
            "     BatchNorm2d-325          [-1, 256, 15, 15]             512\n",
            "            ReLU-326          [-1, 256, 15, 15]               0\n",
            "          Conv2d-327         [-1, 1024, 15, 15]         262,144\n",
            "     BatchNorm2d-328         [-1, 1024, 15, 15]           2,048\n",
            "            ReLU-329         [-1, 1024, 15, 15]               0\n",
            "      Bottleneck-330         [-1, 1024, 15, 15]               0\n",
            "          Conv2d-331          [-1, 256, 15, 15]         262,144\n",
            "     BatchNorm2d-332          [-1, 256, 15, 15]             512\n",
            "            ReLU-333          [-1, 256, 15, 15]               0\n",
            "          Conv2d-334          [-1, 256, 15, 15]         589,824\n",
            "     BatchNorm2d-335          [-1, 256, 15, 15]             512\n",
            "            ReLU-336          [-1, 256, 15, 15]               0\n",
            "          Conv2d-337         [-1, 1024, 15, 15]         262,144\n",
            "     BatchNorm2d-338         [-1, 1024, 15, 15]           2,048\n",
            "            ReLU-339         [-1, 1024, 15, 15]               0\n",
            "      Bottleneck-340         [-1, 1024, 15, 15]               0\n",
            "          Conv2d-341          [-1, 256, 15, 15]         262,144\n",
            "     BatchNorm2d-342          [-1, 256, 15, 15]             512\n",
            "            ReLU-343          [-1, 256, 15, 15]               0\n",
            "          Conv2d-344          [-1, 256, 15, 15]         589,824\n",
            "     BatchNorm2d-345          [-1, 256, 15, 15]             512\n",
            "            ReLU-346          [-1, 256, 15, 15]               0\n",
            "          Conv2d-347         [-1, 1024, 15, 15]         262,144\n",
            "     BatchNorm2d-348         [-1, 1024, 15, 15]           2,048\n",
            "            ReLU-349         [-1, 1024, 15, 15]               0\n",
            "      Bottleneck-350         [-1, 1024, 15, 15]               0\n",
            "          Conv2d-351          [-1, 256, 15, 15]         262,144\n",
            "     BatchNorm2d-352          [-1, 256, 15, 15]             512\n",
            "            ReLU-353          [-1, 256, 15, 15]               0\n",
            "          Conv2d-354          [-1, 256, 15, 15]         589,824\n",
            "     BatchNorm2d-355          [-1, 256, 15, 15]             512\n",
            "            ReLU-356          [-1, 256, 15, 15]               0\n",
            "          Conv2d-357         [-1, 1024, 15, 15]         262,144\n",
            "     BatchNorm2d-358         [-1, 1024, 15, 15]           2,048\n",
            "            ReLU-359         [-1, 1024, 15, 15]               0\n",
            "      Bottleneck-360         [-1, 1024, 15, 15]               0\n",
            "          Conv2d-361          [-1, 256, 15, 15]         262,144\n",
            "     BatchNorm2d-362          [-1, 256, 15, 15]             512\n",
            "            ReLU-363          [-1, 256, 15, 15]               0\n",
            "          Conv2d-364          [-1, 256, 15, 15]         589,824\n",
            "     BatchNorm2d-365          [-1, 256, 15, 15]             512\n",
            "            ReLU-366          [-1, 256, 15, 15]               0\n",
            "          Conv2d-367         [-1, 1024, 15, 15]         262,144\n",
            "     BatchNorm2d-368         [-1, 1024, 15, 15]           2,048\n",
            "            ReLU-369         [-1, 1024, 15, 15]               0\n",
            "      Bottleneck-370         [-1, 1024, 15, 15]               0\n",
            "          Conv2d-371          [-1, 256, 15, 15]         262,144\n",
            "     BatchNorm2d-372          [-1, 256, 15, 15]             512\n",
            "            ReLU-373          [-1, 256, 15, 15]               0\n",
            "          Conv2d-374          [-1, 256, 15, 15]         589,824\n",
            "     BatchNorm2d-375          [-1, 256, 15, 15]             512\n",
            "            ReLU-376          [-1, 256, 15, 15]               0\n",
            "          Conv2d-377         [-1, 1024, 15, 15]         262,144\n",
            "     BatchNorm2d-378         [-1, 1024, 15, 15]           2,048\n",
            "            ReLU-379         [-1, 1024, 15, 15]               0\n",
            "      Bottleneck-380         [-1, 1024, 15, 15]               0\n",
            "          Conv2d-381          [-1, 256, 15, 15]         262,144\n",
            "     BatchNorm2d-382          [-1, 256, 15, 15]             512\n",
            "            ReLU-383          [-1, 256, 15, 15]               0\n",
            "          Conv2d-384          [-1, 256, 15, 15]         589,824\n",
            "     BatchNorm2d-385          [-1, 256, 15, 15]             512\n",
            "            ReLU-386          [-1, 256, 15, 15]               0\n",
            "          Conv2d-387         [-1, 1024, 15, 15]         262,144\n",
            "     BatchNorm2d-388         [-1, 1024, 15, 15]           2,048\n",
            "            ReLU-389         [-1, 1024, 15, 15]               0\n",
            "      Bottleneck-390         [-1, 1024, 15, 15]               0\n",
            "          Conv2d-391          [-1, 256, 15, 15]         262,144\n",
            "     BatchNorm2d-392          [-1, 256, 15, 15]             512\n",
            "            ReLU-393          [-1, 256, 15, 15]               0\n",
            "          Conv2d-394          [-1, 256, 15, 15]         589,824\n",
            "     BatchNorm2d-395          [-1, 256, 15, 15]             512\n",
            "            ReLU-396          [-1, 256, 15, 15]               0\n",
            "          Conv2d-397         [-1, 1024, 15, 15]         262,144\n",
            "     BatchNorm2d-398         [-1, 1024, 15, 15]           2,048\n",
            "            ReLU-399         [-1, 1024, 15, 15]               0\n",
            "      Bottleneck-400         [-1, 1024, 15, 15]               0\n",
            "          Conv2d-401          [-1, 256, 15, 15]         262,144\n",
            "     BatchNorm2d-402          [-1, 256, 15, 15]             512\n",
            "            ReLU-403          [-1, 256, 15, 15]               0\n",
            "          Conv2d-404          [-1, 256, 15, 15]         589,824\n",
            "     BatchNorm2d-405          [-1, 256, 15, 15]             512\n",
            "            ReLU-406          [-1, 256, 15, 15]               0\n",
            "          Conv2d-407         [-1, 1024, 15, 15]         262,144\n",
            "     BatchNorm2d-408         [-1, 1024, 15, 15]           2,048\n",
            "            ReLU-409         [-1, 1024, 15, 15]               0\n",
            "      Bottleneck-410         [-1, 1024, 15, 15]               0\n",
            "          Conv2d-411          [-1, 256, 15, 15]         262,144\n",
            "     BatchNorm2d-412          [-1, 256, 15, 15]             512\n",
            "            ReLU-413          [-1, 256, 15, 15]               0\n",
            "          Conv2d-414          [-1, 256, 15, 15]         589,824\n",
            "     BatchNorm2d-415          [-1, 256, 15, 15]             512\n",
            "            ReLU-416          [-1, 256, 15, 15]               0\n",
            "          Conv2d-417         [-1, 1024, 15, 15]         262,144\n",
            "     BatchNorm2d-418         [-1, 1024, 15, 15]           2,048\n",
            "            ReLU-419         [-1, 1024, 15, 15]               0\n",
            "      Bottleneck-420         [-1, 1024, 15, 15]               0\n",
            "          Conv2d-421          [-1, 256, 15, 15]         262,144\n",
            "     BatchNorm2d-422          [-1, 256, 15, 15]             512\n",
            "            ReLU-423          [-1, 256, 15, 15]               0\n",
            "          Conv2d-424          [-1, 256, 15, 15]         589,824\n",
            "     BatchNorm2d-425          [-1, 256, 15, 15]             512\n",
            "            ReLU-426          [-1, 256, 15, 15]               0\n",
            "          Conv2d-427         [-1, 1024, 15, 15]         262,144\n",
            "     BatchNorm2d-428         [-1, 1024, 15, 15]           2,048\n",
            "            ReLU-429         [-1, 1024, 15, 15]               0\n",
            "      Bottleneck-430         [-1, 1024, 15, 15]               0\n",
            "          Conv2d-431          [-1, 256, 15, 15]         262,144\n",
            "     BatchNorm2d-432          [-1, 256, 15, 15]             512\n",
            "            ReLU-433          [-1, 256, 15, 15]               0\n",
            "          Conv2d-434          [-1, 256, 15, 15]         589,824\n",
            "     BatchNorm2d-435          [-1, 256, 15, 15]             512\n",
            "            ReLU-436          [-1, 256, 15, 15]               0\n",
            "          Conv2d-437         [-1, 1024, 15, 15]         262,144\n",
            "     BatchNorm2d-438         [-1, 1024, 15, 15]           2,048\n",
            "            ReLU-439         [-1, 1024, 15, 15]               0\n",
            "      Bottleneck-440         [-1, 1024, 15, 15]               0\n",
            "          Conv2d-441          [-1, 256, 15, 15]         262,144\n",
            "     BatchNorm2d-442          [-1, 256, 15, 15]             512\n",
            "            ReLU-443          [-1, 256, 15, 15]               0\n",
            "          Conv2d-444          [-1, 256, 15, 15]         589,824\n",
            "     BatchNorm2d-445          [-1, 256, 15, 15]             512\n",
            "            ReLU-446          [-1, 256, 15, 15]               0\n",
            "          Conv2d-447         [-1, 1024, 15, 15]         262,144\n",
            "     BatchNorm2d-448         [-1, 1024, 15, 15]           2,048\n",
            "            ReLU-449         [-1, 1024, 15, 15]               0\n",
            "      Bottleneck-450         [-1, 1024, 15, 15]               0\n",
            "          Conv2d-451          [-1, 256, 15, 15]         262,144\n",
            "     BatchNorm2d-452          [-1, 256, 15, 15]             512\n",
            "            ReLU-453          [-1, 256, 15, 15]               0\n",
            "          Conv2d-454          [-1, 256, 15, 15]         589,824\n",
            "     BatchNorm2d-455          [-1, 256, 15, 15]             512\n",
            "            ReLU-456          [-1, 256, 15, 15]               0\n",
            "          Conv2d-457         [-1, 1024, 15, 15]         262,144\n",
            "     BatchNorm2d-458         [-1, 1024, 15, 15]           2,048\n",
            "            ReLU-459         [-1, 1024, 15, 15]               0\n",
            "      Bottleneck-460         [-1, 1024, 15, 15]               0\n",
            "          Conv2d-461          [-1, 256, 15, 15]         262,144\n",
            "     BatchNorm2d-462          [-1, 256, 15, 15]             512\n",
            "            ReLU-463          [-1, 256, 15, 15]               0\n",
            "          Conv2d-464          [-1, 256, 15, 15]         589,824\n",
            "     BatchNorm2d-465          [-1, 256, 15, 15]             512\n",
            "            ReLU-466          [-1, 256, 15, 15]               0\n",
            "          Conv2d-467         [-1, 1024, 15, 15]         262,144\n",
            "     BatchNorm2d-468         [-1, 1024, 15, 15]           2,048\n",
            "            ReLU-469         [-1, 1024, 15, 15]               0\n",
            "      Bottleneck-470         [-1, 1024, 15, 15]               0\n",
            "          Conv2d-471          [-1, 256, 15, 15]         262,144\n",
            "     BatchNorm2d-472          [-1, 256, 15, 15]             512\n",
            "            ReLU-473          [-1, 256, 15, 15]               0\n",
            "          Conv2d-474          [-1, 256, 15, 15]         589,824\n",
            "     BatchNorm2d-475          [-1, 256, 15, 15]             512\n",
            "            ReLU-476          [-1, 256, 15, 15]               0\n",
            "          Conv2d-477         [-1, 1024, 15, 15]         262,144\n",
            "     BatchNorm2d-478         [-1, 1024, 15, 15]           2,048\n",
            "            ReLU-479         [-1, 1024, 15, 15]               0\n",
            "      Bottleneck-480         [-1, 1024, 15, 15]               0\n",
            "          Conv2d-481          [-1, 512, 15, 15]         524,288\n",
            "     BatchNorm2d-482          [-1, 512, 15, 15]           1,024\n",
            "            ReLU-483          [-1, 512, 15, 15]               0\n",
            "          Conv2d-484            [-1, 512, 8, 8]       2,359,296\n",
            "     BatchNorm2d-485            [-1, 512, 8, 8]           1,024\n",
            "            ReLU-486            [-1, 512, 8, 8]               0\n",
            "          Conv2d-487           [-1, 2048, 8, 8]       1,048,576\n",
            "     BatchNorm2d-488           [-1, 2048, 8, 8]           4,096\n",
            "          Conv2d-489           [-1, 2048, 8, 8]       2,097,152\n",
            "     BatchNorm2d-490           [-1, 2048, 8, 8]           4,096\n",
            "            ReLU-491           [-1, 2048, 8, 8]               0\n",
            "      Bottleneck-492           [-1, 2048, 8, 8]               0\n",
            "          Conv2d-493            [-1, 512, 8, 8]       1,048,576\n",
            "     BatchNorm2d-494            [-1, 512, 8, 8]           1,024\n",
            "            ReLU-495            [-1, 512, 8, 8]               0\n",
            "          Conv2d-496            [-1, 512, 8, 8]       2,359,296\n",
            "     BatchNorm2d-497            [-1, 512, 8, 8]           1,024\n",
            "            ReLU-498            [-1, 512, 8, 8]               0\n",
            "          Conv2d-499           [-1, 2048, 8, 8]       1,048,576\n",
            "     BatchNorm2d-500           [-1, 2048, 8, 8]           4,096\n",
            "            ReLU-501           [-1, 2048, 8, 8]               0\n",
            "      Bottleneck-502           [-1, 2048, 8, 8]               0\n",
            "          Conv2d-503            [-1, 512, 8, 8]       1,048,576\n",
            "     BatchNorm2d-504            [-1, 512, 8, 8]           1,024\n",
            "            ReLU-505            [-1, 512, 8, 8]               0\n",
            "          Conv2d-506            [-1, 512, 8, 8]       2,359,296\n",
            "     BatchNorm2d-507            [-1, 512, 8, 8]           1,024\n",
            "            ReLU-508            [-1, 512, 8, 8]               0\n",
            "          Conv2d-509           [-1, 2048, 8, 8]       1,048,576\n",
            "     BatchNorm2d-510           [-1, 2048, 8, 8]           4,096\n",
            "            ReLU-511           [-1, 2048, 8, 8]               0\n",
            "      Bottleneck-512           [-1, 2048, 8, 8]               0\n",
            "AdaptiveAvgPool2d-513           [-1, 2048, 1, 1]               0\n",
            "================================================================\n",
            "Total params: 58,143,808\n",
            "Trainable params: 58,143,808\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.59\n",
            "Forward/backward pass size (MB): 671.77\n",
            "Params size (MB): 221.80\n",
            "Estimated Total Size (MB): 894.16\n",
            "----------------------------------------------------------------\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-799708373e2f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfirst\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m           \u001b[0mtrain_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    418\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    419\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 420\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8jL9I9cKe-Z"
      },
      "source": [
        "from sklearn.svm import LinearSVC\r\n",
        "from sklearn.metrics import accuracy_score\r\n",
        "\r\n",
        "clf = LinearSVC()\r\n",
        "clf.fit(train_features, train_labels)\r\n",
        "\r\n",
        "pred = clf.predict(test_features)\r\n",
        "print(accuracy_score(test_labels, pred))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}