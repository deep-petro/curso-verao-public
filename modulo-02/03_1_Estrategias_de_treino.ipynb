{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "03_1_Estrategias_de_treino.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "5Xu4l1od4y1N",
        "0WyR3sukIS9D",
        "rsOgJBcofpZN"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "63a6b5d2130f49de995d8b87298f393e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1267a539a61f48b499984017b344826b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e9c52220ba4348fcb03ad3d4c37224be",
              "IPY_MODEL_0f547a258bf4479d8566740d224b482a"
            ]
          }
        },
        "1267a539a61f48b499984017b344826b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e9c52220ba4348fcb03ad3d4c37224be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_157f152f56bb4275ad7417b60248c26e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5b3c87a00bf146f19a4840d708fc0b9d"
          }
        },
        "0f547a258bf4479d8566740d224b482a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a652e14b414541af88d691ef255feead",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170500096/? [00:20&lt;00:00, 52369918.15it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_647ddf9477db401fa19771363e3d95c0"
          }
        },
        "157f152f56bb4275ad7417b60248c26e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5b3c87a00bf146f19a4840d708fc0b9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a652e14b414541af88d691ef255feead": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "647ddf9477db401fa19771363e3d95c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9c4a1ea66ed340d8b0419cfd1b68b07c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5c40fb6eabfc42fa94455f62312251bd",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_501a5e66387e4c8fa7c51c35a2a591b4",
              "IPY_MODEL_70ef5ebd7daf4ccd8a419e8aba4e3f52"
            ]
          }
        },
        "5c40fb6eabfc42fa94455f62312251bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "501a5e66387e4c8fa7c51c35a2a591b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1e9b184b374d40958d822f6556ab4278",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d460f93e9ab14a8db6da01b38fbaffb5"
          }
        },
        "70ef5ebd7daf4ccd8a419e8aba4e3f52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_13b9ca5b94f44bb19bc934eb6bece083",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170500096/? [00:20&lt;00:00, 101312684.17it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c67ab45ebd4940d289eebf389c8441d0"
          }
        },
        "1e9b184b374d40958d822f6556ab4278": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d460f93e9ab14a8db6da01b38fbaffb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "13b9ca5b94f44bb19bc934eb6bece083": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c67ab45ebd4940d289eebf389c8441d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXlS74cg4Ebl"
      },
      "source": [
        "# Estratégias de treino\n",
        "\n",
        "Até agora no curso, vimos somente uma estratégia de treino para redes neurais: o treinamento do zero.\n",
        "Entretanto, há outras formas de se explorar redes neurais.\n",
        "Nessa aula, vamos rever a estratégia treinamento do zero além de apresentar duas novas formas:\n",
        "\n",
        "1.   rede neural como um extrator de características, e\n",
        "2.   *fine-tuning*.\n",
        "\n",
        "Para cada uma dessas estratégias, vamos apresentar sua definição, vantagens e desvantagens.\n",
        "Antes, vamos instalar o Pytorch, importar alguns pacotes e definir funções para carregar os dados.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDFChpaZ4MiW",
        "outputId": "92661a73-adbe-4a28-d184-4f46d933781a"
      },
      "source": [
        "import time, os, sys, numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch import optim\n",
        "from torchsummary import summary\n",
        "\n",
        "\n",
        "import time, os, sys, numpy as np\n",
        "\n",
        "# Test if GPU is avaliable, if not, use cpu instead\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "n = torch.cuda.device_count()\n",
        "devices_ids= list(range(n))\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uF4QkjwG4RQI"
      },
      "source": [
        "def load_data_cifar10(batch_size, resize=None, root=os.path.join(\n",
        "        '~', '.pytorch', 'datasets', 'fashion-mnist')):\n",
        "    \"\"\"Download the Cifar10-MNIST dataset and then load into memory.\"\"\"\n",
        "    root = os.path.expanduser(root)\n",
        "    transformer = []\n",
        "    if resize:\n",
        "        transformer += [torchvision.transforms.Resize(resize)]\n",
        "    transformer += [torchvision.transforms.ToTensor()]\n",
        "    transformer = torchvision.transforms.Compose(transformer)\n",
        "\n",
        "    mnist_train = torchvision.datasets.CIFAR10(root=root, train=True,download=True,transform=transformer)\n",
        "    mnist_test = torchvision.datasets.CIFAR10(root=root, train=False,download=True,transform=transformer)\n",
        "    num_workers = 0 if sys.platform.startswith('win32') else 4\n",
        "\n",
        "\n",
        "\n",
        "    train_iter = torch.utils.data.DataLoader(mnist_train,\n",
        "                                  batch_size, shuffle=True,\n",
        "                                  num_workers=num_workers)\n",
        "    test_iter = torch.utils.data.DataLoader(mnist_test,\n",
        "                                 batch_size, shuffle=False,\n",
        "                                 num_workers=num_workers)\n",
        "    return train_iter, test_iter\n",
        "\n",
        "# funções básicas\n",
        "def _get_batch(batch):\n",
        "    \"\"\"Return features and labels on ctx.\"\"\"\n",
        "    features, labels = batch\n",
        "    if labels.type() != features.type():\n",
        "        labels = labels.type(features.type())\n",
        "    return (torch.nn.DataParallel(features, device_ids=devices_ids),\n",
        "            torch.nn.DataParallel(labels, device_ids=devices_ids), features.shape[0])\n",
        "\n",
        "# Função usada para calcular acurácia\n",
        "def evaluate_accuracy(data_iter, net, loss):\n",
        "    \"\"\"Evaluate accuracy of a model on the given data set.\"\"\"\n",
        "\n",
        "    acc_sum, n, l = torch.Tensor([0]), 0, 0\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "      for X, y in data_iter:\n",
        "          #y = y.astype('float32')\n",
        "          X, y = X.to(device), y.to(device)\n",
        "          y_hat = net(X)\n",
        "          l += loss(y_hat, y).sum()\n",
        "          acc_sum += (y_hat.argmax(axis=1) == y).sum().item()\n",
        "          n += y.size()[0]\n",
        "\n",
        "    return acc_sum.item() / n, l.item() / len(data_iter)\n",
        "  \n",
        "# Função usada no treinamento e validação da rede\n",
        "def train_validate(net, train_iter, test_iter, batch_size, trainer, loss,\n",
        "                   num_epochs):\n",
        "    print('training on', device)\n",
        "    for epoch in range(num_epochs):\n",
        "        net.train()\n",
        "        train_l_sum, train_acc_sum, n, start = 0.0, 0.0, 0, time.time()\n",
        "        for X, y in train_iter:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            y_hat = net(X)\n",
        "            trainer.zero_grad()\n",
        "            l = loss(y_hat, y).sum()\n",
        "            l.backward()\n",
        "            trainer.step()\n",
        "            train_l_sum += l.item()\n",
        "            train_acc_sum += (y_hat.argmax(axis=1) == y).sum().item()\n",
        "            n += y.size()[0]\n",
        "        test_acc, test_loss = evaluate_accuracy(test_iter, net, loss)\n",
        "        print('epoch %d, train loss %.4f, train acc %.3f, test loss %.4f, '\n",
        "              'test acc %.3f, time %.1f sec'\n",
        "              % (epoch + 1, train_l_sum / len(train_iter), train_acc_sum / n, test_loss, \n",
        "                 test_acc, time.time() - start))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Xu4l1od4y1N"
      },
      "source": [
        "## Treinamento do zero\n",
        "\n",
        "Como dito anteriormente, essa foi a única estratégia vista até o momento no curso.\n",
        "Nessa estratégia, uma rede neural é proposta, **inicializada com pesos aleatórios** e treinada até convergir.\n",
        "A **vantagem** dessa estratégia é liberdade para definir como quiser a arquitetura da rede e seus hiper-parâmetros\n",
        "Por outro lado, a **desvantagem** é que essa estratégia requer muitos dados para convergir a rede inicializada aleatoriamente.\n",
        "Logo, se tivermos poucos dados, essa não é a estratégia mais recomendada.\n",
        "Abaixo, uma representação visual dessa estratégia.\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img width=600 src=\"https://drive.google.com/uc?export=view&id=1_bBQjyoDqB3kQMncmVkuJwSxDs3rqUmM\">\n",
        "</p>\n",
        "\n",
        "Apesar de já termos visto essa estratégia na prática, vamos vê-la aqui novamente para efeitos de comparação com as outras técnicas. Para tal, vamos, primeiro, definimos a arquitetura da [AlexNet](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZAEDlZ-DgGd"
      },
      "source": [
        "class AlexNet(nn.Module):\n",
        "    def __init__(self, input_channels, classes=10, **kwargs):\n",
        "        super(AlexNet, self).__init__(**kwargs)\n",
        "        self.convs = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=input_channels, out_channels=96, kernel_size=11, stride=4, padding=0),   # entrada: (b, 3, 227, 227) e saida: (b, 96, 55, 55)\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, padding=0),                                   # entrada: (b, 96, 55, 55) e saida: (b, 96, 27, 27)\n",
        "\n",
        "            nn.Conv2d(in_channels=96, out_channels=256, kernel_size=5, stride=1, padding=2),  # entrada: (b, 96, 27, 27) e saida: (b, 256, 27, 27)\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, padding=0),                                   # entrada: (b, 256, 27, 27) e saida: (b, 256, 13, 13)\n",
        "            nn.Conv2d(in_channels=256, out_channels=384, kernel_size=3, stride=1, padding=1), # entrada: (b, 256, 13, 13) e saida: (b, 384, 13, 13)\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=384, out_channels=384, kernel_size=3, stride=1, padding=1), # entrada: (b, 384, 13, 13) e saida: (b, 384, 13, 13)\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, stride=1, padding=1), # entrada: (b, 384, 13, 13) e saida: (b, 256, 13, 13)\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, padding=0)                                    # entrada: (b, 256, 13, 13) e saida: (b, 256, 6, 6)\n",
        "        )\n",
        "\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Flatten(),                                                                     # entrada: (b, 256, 13, 13) e saida: (b, 256*6*6) = (b, 9216)\n",
        "            nn.Linear(9216, 4096),                                                             # entrada: (b, 9216) e saida: (b, 4096)\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(4096, 4096),                                                             # entrada: (b, 4096) e saida: (b, 4096)\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(4096, classes)                                                          # entrada: (b, 4096) e saida: (b, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.convs(x)\n",
        "        x = self.features(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "63a6b5d2130f49de995d8b87298f393e",
            "1267a539a61f48b499984017b344826b",
            "e9c52220ba4348fcb03ad3d4c37224be",
            "0f547a258bf4479d8566740d224b482a",
            "157f152f56bb4275ad7417b60248c26e",
            "5b3c87a00bf146f19a4840d708fc0b9d",
            "a652e14b414541af88d691ef255feead",
            "647ddf9477db401fa19771363e3d95c0"
          ]
        },
        "id": "9Wr5rH-KMNZo",
        "outputId": "5b781524-ed97-460c-e42d-6d7a1ad06560"
      },
      "source": [
        "# parâmetros: número de epochs, learning rate (ou taxa de aprendizado), \n",
        "# tamanho do batch, e lambda do weight decay\n",
        "num_epochs, lr, batch_size, wd_lambda = 20, 0.01, 100, 0.0001\n",
        "\n",
        "\n",
        "# rede baseada na AlexNet-5 \n",
        "net = AlexNet(3, 10)\n",
        "\n",
        "# Sending model to device\n",
        "net.to(device)\n",
        "print(summary(net,(3, 227, 227))) # visualize number of parameters' net, output of each layer and total mega bytes necessary for forward pass\n",
        "                                # and stored weights. \n",
        "\n",
        "# função de custo (ou loss)\n",
        "loss = nn.CrossEntropyLoss()\n",
        "\n",
        "# carregamento do dado: mnist\n",
        "train_iter, test_iter = load_data_cifar10(batch_size, resize=227)\n",
        "\n",
        "# trainer do gluon\n",
        "trainer = optim.SGD(net.parameters(), lr=lr, weight_decay=wd_lambda, momentum=0.9)\n",
        "\n",
        "# treinamento e validação via Pytorch\n",
        "train_validate(net, train_iter, test_iter, batch_size, trainer, loss, \n",
        "                num_epochs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 96, 55, 55]          34,944\n",
            "              ReLU-2           [-1, 96, 55, 55]               0\n",
            "         MaxPool2d-3           [-1, 96, 27, 27]               0\n",
            "            Conv2d-4          [-1, 256, 27, 27]         614,656\n",
            "              ReLU-5          [-1, 256, 27, 27]               0\n",
            "         MaxPool2d-6          [-1, 256, 13, 13]               0\n",
            "            Conv2d-7          [-1, 384, 13, 13]         885,120\n",
            "              ReLU-8          [-1, 384, 13, 13]               0\n",
            "            Conv2d-9          [-1, 384, 13, 13]       1,327,488\n",
            "             ReLU-10          [-1, 384, 13, 13]               0\n",
            "           Conv2d-11          [-1, 256, 13, 13]         884,992\n",
            "             ReLU-12          [-1, 256, 13, 13]               0\n",
            "        MaxPool2d-13            [-1, 256, 6, 6]               0\n",
            "          Flatten-14                 [-1, 9216]               0\n",
            "           Linear-15                 [-1, 4096]      37,752,832\n",
            "             ReLU-16                 [-1, 4096]               0\n",
            "          Dropout-17                 [-1, 4096]               0\n",
            "           Linear-18                 [-1, 4096]      16,781,312\n",
            "             ReLU-19                 [-1, 4096]               0\n",
            "          Dropout-20                 [-1, 4096]               0\n",
            "           Linear-21                   [-1, 10]          40,970\n",
            "================================================================\n",
            "Total params: 58,322,314\n",
            "Trainable params: 58,322,314\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.59\n",
            "Forward/backward pass size (MB): 11.11\n",
            "Params size (MB): 222.48\n",
            "Estimated Total Size (MB): 234.18\n",
            "----------------------------------------------------------------\n",
            "None\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /root/.pytorch/datasets/fashion-mnist/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "63a6b5d2130f49de995d8b87298f393e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /root/.pytorch/datasets/fashion-mnist/cifar-10-python.tar.gz to /root/.pytorch/datasets/fashion-mnist\n",
            "Files already downloaded and verified\n",
            "training on cuda\n",
            "epoch 1, train loss 2.2015, train acc 0.161, test loss 1.9719, test acc 0.281, time 92.1 sec\n",
            "epoch 2, train loss 1.7785, train acc 0.339, test loss 1.5453, test acc 0.423, time 93.5 sec\n",
            "epoch 3, train loss 1.4151, train acc 0.483, test loss 1.2054, test acc 0.574, time 94.3 sec\n",
            "epoch 4, train loss 1.1467, train acc 0.591, test loss 0.9854, test acc 0.656, time 94.4 sec\n",
            "epoch 5, train loss 0.9382, train acc 0.671, test loss 0.8815, test acc 0.693, time 94.5 sec\n",
            "epoch 6, train loss 0.7706, train acc 0.734, test loss 0.7898, test acc 0.728, time 95.9 sec\n",
            "epoch 7, train loss 0.6444, train acc 0.777, test loss 0.6734, test acc 0.770, time 95.3 sec\n",
            "epoch 8, train loss 0.5413, train acc 0.812, test loss 0.6623, test acc 0.779, time 95.8 sec\n",
            "epoch 9, train loss 0.4430, train acc 0.846, test loss 0.6259, test acc 0.789, time 98.7 sec\n",
            "epoch 10, train loss 0.3558, train acc 0.876, test loss 0.6036, test acc 0.799, time 99.4 sec\n",
            "epoch 11, train loss 0.2787, train acc 0.903, test loss 0.6869, test acc 0.795, time 99.3 sec\n",
            "epoch 12, train loss 0.2203, train acc 0.923, test loss 0.6432, test acc 0.808, time 99.4 sec\n",
            "epoch 13, train loss 0.1925, train acc 0.934, test loss 0.7119, test acc 0.801, time 97.3 sec\n",
            "epoch 14, train loss 0.1473, train acc 0.950, test loss 0.7386, test acc 0.807, time 97.1 sec\n",
            "epoch 15, train loss 0.1273, train acc 0.957, test loss 0.8623, test acc 0.805, time 97.3 sec\n",
            "epoch 16, train loss 0.1147, train acc 0.961, test loss 0.7945, test acc 0.803, time 98.0 sec\n",
            "epoch 17, train loss 0.0930, train acc 0.969, test loss 0.8906, test acc 0.813, time 97.9 sec\n",
            "epoch 18, train loss 0.0865, train acc 0.971, test loss 0.8490, test acc 0.810, time 99.5 sec\n",
            "epoch 19, train loss 0.0689, train acc 0.977, test loss 0.9094, test acc 0.806, time 101.2 sec\n",
            "epoch 20, train loss 0.0683, train acc 0.977, test loss 0.8422, test acc 0.816, time 100.3 sec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgJwhj2SSGFB"
      },
      "source": [
        "É muito comum se usar redes já existentes para aprender características em novos dados.\n",
        "Por isso, muitos frameworks já deixam as arquiteturas mais famosas pré-implementadas para que possam ser usadas.\n",
        "\n",
        "No Pytorch, podemos importar uma rede [AlexNet](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf) usando o pacote [torchvision.models](https://pytorch.org/docs/stable/torchvision/models.html#torchvision-models) do Pytorch.\n",
        "Há várias arquiteturas pré-definidas nessa biblioteca, incluindo várias [DenseNets](https://arxiv.org/pdf/1608.06993.pdf) e [ResNets](https://arxiv.org/abs/1603.05027), [VGGs](https://arxiv.org/abs/1409.1556), [SqueezeNets](https://arxiv.org/abs/1602.07360), etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "9c4a1ea66ed340d8b0419cfd1b68b07c",
            "5c40fb6eabfc42fa94455f62312251bd",
            "501a5e66387e4c8fa7c51c35a2a591b4",
            "70ef5ebd7daf4ccd8a419e8aba4e3f52",
            "1e9b184b374d40958d822f6556ab4278",
            "d460f93e9ab14a8db6da01b38fbaffb5",
            "13b9ca5b94f44bb19bc934eb6bece083",
            "c67ab45ebd4940d289eebf389c8441d0"
          ]
        },
        "id": "f3u7xCEQM0qF",
        "outputId": "576b9bbe-98b0-4f5b-ce44-5ff4eae067fa"
      },
      "source": [
        "# parâmetros: número de epochs, learning rate (ou taxa de aprendizado), \n",
        "# tamanho do batch, e lambda do weight decay\n",
        "num_epochs, lr, batch_size, wd_lambda = 20, 0.01, 100, 0.0001\n",
        "\n",
        "# rede baseada na AlexNet-5 \n",
        "net = torchvision.models.alexnet(num_classes=10)\n",
        "\n",
        "# Sending model to device\n",
        "net.to(device)\n",
        "print(summary(net,(3,227,227))) # visualize number of parameters' net, output of each layer and total mega bytes necessary for forward pass\n",
        "                                # and stored weights. \n",
        "\n",
        "# função de custo (ou loss)\n",
        "loss = nn.CrossEntropyLoss()\n",
        "\n",
        "# carregamento do dado: mnist\n",
        "train_iter, test_iter = load_data_cifar10(batch_size, resize=227)\n",
        "\n",
        "# trainer do gluon\n",
        "trainer = optim.SGD(net.parameters(), lr=lr, weight_decay=wd_lambda, momentum=0.9)\n",
        "\n",
        "# treinamento e validação via Pytorch\n",
        "train_validate(net, train_iter, test_iter, batch_size, trainer, loss, \n",
        "                num_epochs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 56, 56]          23,296\n",
            "              ReLU-2           [-1, 64, 56, 56]               0\n",
            "         MaxPool2d-3           [-1, 64, 27, 27]               0\n",
            "            Conv2d-4          [-1, 192, 27, 27]         307,392\n",
            "              ReLU-5          [-1, 192, 27, 27]               0\n",
            "         MaxPool2d-6          [-1, 192, 13, 13]               0\n",
            "            Conv2d-7          [-1, 384, 13, 13]         663,936\n",
            "              ReLU-8          [-1, 384, 13, 13]               0\n",
            "            Conv2d-9          [-1, 256, 13, 13]         884,992\n",
            "             ReLU-10          [-1, 256, 13, 13]               0\n",
            "           Conv2d-11          [-1, 256, 13, 13]         590,080\n",
            "             ReLU-12          [-1, 256, 13, 13]               0\n",
            "        MaxPool2d-13            [-1, 256, 6, 6]               0\n",
            "AdaptiveAvgPool2d-14            [-1, 256, 6, 6]               0\n",
            "          Dropout-15                 [-1, 9216]               0\n",
            "           Linear-16                 [-1, 4096]      37,752,832\n",
            "             ReLU-17                 [-1, 4096]               0\n",
            "          Dropout-18                 [-1, 4096]               0\n",
            "           Linear-19                 [-1, 4096]      16,781,312\n",
            "             ReLU-20                 [-1, 4096]               0\n",
            "           Linear-21                   [-1, 10]          40,970\n",
            "================================================================\n",
            "Total params: 57,044,810\n",
            "Trainable params: 57,044,810\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.59\n",
            "Forward/backward pass size (MB): 8.48\n",
            "Params size (MB): 217.61\n",
            "Estimated Total Size (MB): 226.68\n",
            "----------------------------------------------------------------\n",
            "None\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /root/.pytorch/datasets/fashion-mnist/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9c4a1ea66ed340d8b0419cfd1b68b07c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /root/.pytorch/datasets/fashion-mnist/cifar-10-python.tar.gz to /root/.pytorch/datasets/fashion-mnist\n",
            "Files already downloaded and verified\n",
            "training on cuda\n",
            "epoch 1, train loss 2.2569, train acc 0.132, test loss 2.0560, test acc 0.233, time 87.3 sec\n",
            "epoch 2, train loss 1.8570, train acc 0.312, test loss 1.5836, test acc 0.414, time 87.2 sec\n",
            "epoch 3, train loss 1.4649, train acc 0.463, test loss 1.2912, test acc 0.530, time 88.2 sec\n",
            "epoch 4, train loss 1.2168, train acc 0.564, test loss 1.1152, test acc 0.600, time 88.2 sec\n",
            "epoch 5, train loss 0.9965, train acc 0.651, test loss 0.9834, test acc 0.658, time 88.5 sec\n",
            "epoch 6, train loss 0.8407, train acc 0.706, test loss 0.8171, test acc 0.722, time 88.8 sec\n",
            "epoch 7, train loss 0.7193, train acc 0.749, test loss 0.7321, test acc 0.749, time 88.4 sec\n",
            "epoch 8, train loss 0.6326, train acc 0.779, test loss 0.6461, test acc 0.778, time 88.1 sec\n",
            "epoch 9, train loss 0.5552, train acc 0.805, test loss 0.6047, test acc 0.793, time 88.2 sec\n",
            "epoch 10, train loss 0.4882, train acc 0.830, test loss 0.6147, test acc 0.788, time 88.2 sec\n",
            "epoch 11, train loss 0.4301, train acc 0.850, test loss 0.5401, test acc 0.815, time 88.5 sec\n",
            "epoch 12, train loss 0.3753, train acc 0.869, test loss 0.5618, test acc 0.809, time 88.5 sec\n",
            "epoch 13, train loss 0.3325, train acc 0.881, test loss 0.5655, test acc 0.813, time 88.2 sec\n",
            "epoch 14, train loss 0.2878, train acc 0.898, test loss 0.5629, test acc 0.827, time 88.6 sec\n",
            "epoch 15, train loss 0.2535, train acc 0.911, test loss 0.5592, test acc 0.825, time 88.7 sec\n",
            "epoch 16, train loss 0.2283, train acc 0.920, test loss 0.5841, test acc 0.827, time 88.7 sec\n",
            "epoch 17, train loss 0.2010, train acc 0.929, test loss 0.6103, test acc 0.816, time 88.4 sec\n",
            "epoch 18, train loss 0.1835, train acc 0.936, test loss 0.6266, test acc 0.816, time 88.6 sec\n",
            "epoch 19, train loss 0.1588, train acc 0.945, test loss 0.6158, test acc 0.826, time 88.6 sec\n",
            "epoch 20, train loss 0.1472, train acc 0.949, test loss 0.7042, test acc 0.814, time 88.0 sec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WyR3sukIS9D"
      },
      "source": [
        "## Extrator de características\n",
        "\n",
        "A terceira e última estratégia, mostrada na figura abaixo, é usar uma rede neural pré-treinada em algum dataset grande para extrair características de um outro dataset. Essa estratégia é preferível quando o dataset que se quer extrair as *features* tem muito poucas amostras, inviabilizando o treinamento ou *fine-tuning* da rede.\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img width=600 src=\"https://drive.google.com/uc?export=view&id=1pWGfQIAeOODIvm-IQ7De4kl60XpRYbb5\">\n",
        "</p>\n",
        "\n",
        "Existem duas formas de se explorar essa estratégia. A primeira consiste em substituir e treinar somente a última camada da rede neural. Nessa primeira forma, todas as outras camadas da rede ficam com *learning rate* 0, ou seja, não aprendem nada, e são somente usadas como codificadores/extratores de características. A segunda forma, *features* das imagens do dataset que se quer classificar são extraídas da penúltima camada da rede pré-treinada (geralmente, a camada antes da camada de classificação). Essas *features* são então usadas para se treinar um agoritmo externo (como um SVM ou *random forest*), que então classifica o dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VLBe7z2HmNK",
        "outputId": "ba0e5ad7-9991-4e19-dce3-71d816aa7e55"
      },
      "source": [
        "# rede baseada na AlexNet\n",
        "net = torchvision.models.alexnet(pretrained=True)\n",
        "\n",
        "# Sending model to device\n",
        "net.to(device)\n",
        "\n",
        "for param in net.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "print(summary(net, (3, 227, 227)))\n",
        "\n",
        "num_ftrs = net.classifier[6].in_features\n",
        "net.classifier[6] = nn.Linear(num_ftrs,10) # Alterando a última layer para retornar 10 classes ao invés de 1000\n",
        "\n",
        "# Sending model to device\n",
        "net.to(device)\n",
        "\n",
        "# Verifique no output a última camada do classifier, podemos ver que sua saída é 10\n",
        "print(net)\n",
        "\n",
        "# Podemos ver que este output mostra que apenas  40970 parâmetros serão treinados. Ou seja, somente a última camada\n",
        "print(summary(net, (3,227,227))) \n",
        "\n",
        "# Código retirado de https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html\n",
        "\n",
        "# Gather the parameters to be optimized/updated in this run. If we are\n",
        "#  finetuning we will be updating all parameters. However, if we are\n",
        "#  doing feature extract method, we will only update the parameters\n",
        "#  that we have just initialized, i.e. the parameters with requires_grad\n",
        "#  is True.\n",
        "print(\"Params to learn: \")\n",
        "\n",
        "params_to_update = []\n",
        "for name,param in net.named_parameters():\n",
        "    if param.requires_grad == True:\n",
        "        params_to_update.append(param)\n",
        "        print(\"\\t\",name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 56, 56]          23,296\n",
            "              ReLU-2           [-1, 64, 56, 56]               0\n",
            "         MaxPool2d-3           [-1, 64, 27, 27]               0\n",
            "            Conv2d-4          [-1, 192, 27, 27]         307,392\n",
            "              ReLU-5          [-1, 192, 27, 27]               0\n",
            "         MaxPool2d-6          [-1, 192, 13, 13]               0\n",
            "            Conv2d-7          [-1, 384, 13, 13]         663,936\n",
            "              ReLU-8          [-1, 384, 13, 13]               0\n",
            "            Conv2d-9          [-1, 256, 13, 13]         884,992\n",
            "             ReLU-10          [-1, 256, 13, 13]               0\n",
            "           Conv2d-11          [-1, 256, 13, 13]         590,080\n",
            "             ReLU-12          [-1, 256, 13, 13]               0\n",
            "        MaxPool2d-13            [-1, 256, 6, 6]               0\n",
            "AdaptiveAvgPool2d-14            [-1, 256, 6, 6]               0\n",
            "          Dropout-15                 [-1, 9216]               0\n",
            "           Linear-16                 [-1, 4096]      37,752,832\n",
            "             ReLU-17                 [-1, 4096]               0\n",
            "          Dropout-18                 [-1, 4096]               0\n",
            "           Linear-19                 [-1, 4096]      16,781,312\n",
            "             ReLU-20                 [-1, 4096]               0\n",
            "           Linear-21                 [-1, 1000]       4,097,000\n",
            "================================================================\n",
            "Total params: 61,100,840\n",
            "Trainable params: 0\n",
            "Non-trainable params: 61,100,840\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.59\n",
            "Forward/backward pass size (MB): 8.49\n",
            "Params size (MB): 233.08\n",
            "Estimated Total Size (MB): 242.16\n",
            "----------------------------------------------------------------\n",
            "None\n",
            "AlexNet(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): ReLU(inplace=True)\n",
            "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
            "  (classifier): Sequential(\n",
            "    (0): Dropout(p=0.5, inplace=False)\n",
            "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Dropout(p=0.5, inplace=False)\n",
            "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 56, 56]          23,296\n",
            "              ReLU-2           [-1, 64, 56, 56]               0\n",
            "         MaxPool2d-3           [-1, 64, 27, 27]               0\n",
            "            Conv2d-4          [-1, 192, 27, 27]         307,392\n",
            "              ReLU-5          [-1, 192, 27, 27]               0\n",
            "         MaxPool2d-6          [-1, 192, 13, 13]               0\n",
            "            Conv2d-7          [-1, 384, 13, 13]         663,936\n",
            "              ReLU-8          [-1, 384, 13, 13]               0\n",
            "            Conv2d-9          [-1, 256, 13, 13]         884,992\n",
            "             ReLU-10          [-1, 256, 13, 13]               0\n",
            "           Conv2d-11          [-1, 256, 13, 13]         590,080\n",
            "             ReLU-12          [-1, 256, 13, 13]               0\n",
            "        MaxPool2d-13            [-1, 256, 6, 6]               0\n",
            "AdaptiveAvgPool2d-14            [-1, 256, 6, 6]               0\n",
            "          Dropout-15                 [-1, 9216]               0\n",
            "           Linear-16                 [-1, 4096]      37,752,832\n",
            "             ReLU-17                 [-1, 4096]               0\n",
            "          Dropout-18                 [-1, 4096]               0\n",
            "           Linear-19                 [-1, 4096]      16,781,312\n",
            "             ReLU-20                 [-1, 4096]               0\n",
            "           Linear-21                   [-1, 10]          40,970\n",
            "================================================================\n",
            "Total params: 57,044,810\n",
            "Trainable params: 40,970\n",
            "Non-trainable params: 57,003,840\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.59\n",
            "Forward/backward pass size (MB): 8.48\n",
            "Params size (MB): 217.61\n",
            "Estimated Total Size (MB): 226.68\n",
            "----------------------------------------------------------------\n",
            "None\n",
            "Params to learn: \n",
            "\t classifier.6.weight\n",
            "\t classifier.6.bias\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fk0epQ2PDb0",
        "outputId": "7538a430-fc04-4b26-e1da-4de225349e42"
      },
      "source": [
        "# Treinando a última camada da rede acima\n",
        "# parâmetros: número de epochs, learning rate (ou taxa de aprendizado), \n",
        "# tamanho do batch, e lambda do weight decay\n",
        "num_epochs, lr, batch_size, wd_lambda = 20, 0.001, 100, 0.0001\n",
        "\n",
        "# função de custo (ou loss)\n",
        "loss = nn.CrossEntropyLoss()\n",
        "\n",
        "# carregamento do dado: mnist\n",
        "train_iter, test_iter = load_data_cifar10(batch_size, resize=227)\n",
        "\n",
        "# trainer do gluon\n",
        "trainer = optim.SGD(params_to_update, lr=lr, weight_decay=wd_lambda, momentum=0.9)\n",
        "\n",
        "# treinamento e validação via Pytorch\n",
        "train_validate(net, train_iter, test_iter, batch_size, trainer, loss, \n",
        "                num_epochs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "training on cuda\n",
            "epoch 1, train loss 1.3262, train acc 0.534, test loss 1.0916, test acc 0.610, time 86.6 sec\n",
            "epoch 2, train loss 1.1642, train acc 0.588, test loss 0.9961, test acc 0.654, time 86.8 sec\n",
            "epoch 3, train loss 1.1277, train acc 0.602, test loss 0.9634, test acc 0.662, time 86.9 sec\n",
            "epoch 4, train loss 1.1151, train acc 0.606, test loss 0.9462, test acc 0.672, time 86.8 sec\n",
            "epoch 5, train loss 1.0945, train acc 0.614, test loss 0.9265, test acc 0.676, time 86.7 sec\n",
            "epoch 6, train loss 1.0882, train acc 0.618, test loss 0.9345, test acc 0.671, time 86.8 sec\n",
            "epoch 7, train loss 1.0796, train acc 0.618, test loss 0.9326, test acc 0.678, time 86.5 sec\n",
            "epoch 8, train loss 1.0778, train acc 0.619, test loss 0.8997, test acc 0.684, time 86.5 sec\n",
            "epoch 9, train loss 1.0652, train acc 0.626, test loss 0.9065, test acc 0.679, time 86.6 sec\n",
            "epoch 10, train loss 1.0652, train acc 0.624, test loss 0.8911, test acc 0.687, time 86.8 sec\n",
            "epoch 11, train loss 1.0613, train acc 0.623, test loss 0.9190, test acc 0.674, time 87.0 sec\n",
            "epoch 12, train loss 1.0560, train acc 0.625, test loss 0.9070, test acc 0.678, time 86.6 sec\n",
            "epoch 13, train loss 1.0552, train acc 0.627, test loss 0.8888, test acc 0.686, time 86.7 sec\n",
            "epoch 14, train loss 1.0525, train acc 0.627, test loss 0.9140, test acc 0.673, time 86.8 sec\n",
            "epoch 15, train loss 1.0493, train acc 0.628, test loss 0.8974, test acc 0.684, time 86.7 sec\n",
            "epoch 16, train loss 1.0452, train acc 0.632, test loss 0.9008, test acc 0.683, time 86.6 sec\n",
            "epoch 17, train loss 1.0462, train acc 0.631, test loss 0.8753, test acc 0.693, time 86.6 sec\n",
            "epoch 18, train loss 1.0478, train acc 0.630, test loss 0.8919, test acc 0.681, time 86.8 sec\n",
            "epoch 19, train loss 1.0452, train acc 0.630, test loss 0.9101, test acc 0.679, time 86.5 sec\n",
            "epoch 20, train loss 1.0377, train acc 0.634, test loss 0.8619, test acc 0.698, time 86.9 sec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozt5EPQmSsx1",
        "outputId": "82b0c52f-afb0-4324-f260-d832917ac1b5"
      },
      "source": [
        "# parâmetros: número de epochs, learning rate (ou taxa de aprendizado), \n",
        "# tamanho do batch, e lambda do weight decay\n",
        "num_epochs, lr, batch_size, wd_lambda = 20, 0.01, 100, 0.0001\n",
        "\n",
        "# rede baseada na AlexNet-5 \n",
        "net = torchvision.models.alexnet(pretrained=True)\n",
        "\n",
        "# Sending model to device\n",
        "net.to(device)\n",
        "\n",
        "# carregamento do dado: fashion mnist\n",
        "train_iter, test_iter = load_data_cifar10(batch_size, resize=227)  \n",
        "\n",
        "# remove last fully-connected layer\n",
        "new_classifier = nn.Sequential(*list(net.classifier.children())[:-1])\n",
        "net.classifier = new_classifier\n",
        "\n",
        "print(summary(net,(3,227,227))) # visualize number of parameters' net, output of each layer and total mega bytes necessary for forward pass\n",
        "                                # and stored weights. \n",
        "\n",
        "first = True    \n",
        "with torch.no_grad():\n",
        "    for X, y in train_iter:\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        features = net(X)\n",
        "        if first is True:\n",
        "          train_features = features.cpu().numpy()\n",
        "          train_labels = y.cpu().numpy()\n",
        "          first = False\n",
        "        else:\n",
        "          train_features = np.concatenate((train_features, features.cpu().numpy()))\n",
        "          train_labels = np.concatenate((train_labels, y.cpu().numpy()))\n",
        "\n",
        "\n",
        "first = True    \n",
        "with torch.no_grad():\n",
        "    for X, y in test_iter:\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        features = net(X)\n",
        "        if first is True:\n",
        "          test_features = features.cpu().numpy()\n",
        "          test_labels = y.cpu().numpy()\n",
        "          first = False\n",
        "        else:\n",
        "          test_features = np.concatenate((test_features, features.cpu().numpy()))\n",
        "          test_labels = np.concatenate((test_labels, y.cpu().numpy()))\n",
        "\n",
        "          \n",
        "print(train_features.shape, test_features.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 56, 56]          23,296\n",
            "              ReLU-2           [-1, 64, 56, 56]               0\n",
            "         MaxPool2d-3           [-1, 64, 27, 27]               0\n",
            "            Conv2d-4          [-1, 192, 27, 27]         307,392\n",
            "              ReLU-5          [-1, 192, 27, 27]               0\n",
            "         MaxPool2d-6          [-1, 192, 13, 13]               0\n",
            "            Conv2d-7          [-1, 384, 13, 13]         663,936\n",
            "              ReLU-8          [-1, 384, 13, 13]               0\n",
            "            Conv2d-9          [-1, 256, 13, 13]         884,992\n",
            "             ReLU-10          [-1, 256, 13, 13]               0\n",
            "           Conv2d-11          [-1, 256, 13, 13]         590,080\n",
            "             ReLU-12          [-1, 256, 13, 13]               0\n",
            "        MaxPool2d-13            [-1, 256, 6, 6]               0\n",
            "AdaptiveAvgPool2d-14            [-1, 256, 6, 6]               0\n",
            "          Dropout-15                 [-1, 9216]               0\n",
            "           Linear-16                 [-1, 4096]      37,752,832\n",
            "             ReLU-17                 [-1, 4096]               0\n",
            "          Dropout-18                 [-1, 4096]               0\n",
            "           Linear-19                 [-1, 4096]      16,781,312\n",
            "             ReLU-20                 [-1, 4096]               0\n",
            "================================================================\n",
            "Total params: 57,003,840\n",
            "Trainable params: 57,003,840\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.59\n",
            "Forward/backward pass size (MB): 8.48\n",
            "Params size (MB): 217.45\n",
            "Estimated Total Size (MB): 226.52\n",
            "----------------------------------------------------------------\n",
            "None\n",
            "(50000, 4096) (10000, 4096)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BR7LqiOTY6Tc",
        "outputId": "76c66d61-8dab-46cd-cfd3-58152fc3324a"
      },
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "clf = LinearSVC()\n",
        "clf.fit(train_features, train_labels)\n",
        "\n",
        "pred = clf.predict(test_features)\n",
        "print(accuracy_score(test_labels, pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.5193\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsOgJBcofpZN"
      },
      "source": [
        "## *Fine-tuning*\n",
        "\n",
        "A segunda estratégia é chamada de *fine-tuning*, e é comumente classificada como um estratégia de *transfer learning*, onde o aprendizado é transferido entre datasets.\n",
        "Especificamente, esta estratégia, representada na figura abaixo, tenta usar um modelo pré-treinado aprendido anteriormente em algum dataset (geralmente muito grande, como o [ImageNet](http://www.image-net.org/)) para classificar outro conjunto de dados diferentes (geralmente com poucas amostras).\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img width=600 src=\"https://drive.google.com/uc?export=view&id=1CoOfpMcQAEl9YAL0lgW11LLYpDcnL4dQ\">\n",
        "</p>\n",
        "\n",
        "Como esses dados podem possuir características diferentes, treinamos a rede usando um *learning rate* pequeno, apenas para fazer pequenos ajustes nos pesos. Entretanto, como esses datasets geralmente tem número e classes diferentes, a última camada não é usada nessa transferência de peso e, geralmente, é inicializada aleatoriamente (e por isso, tem um *learning rate* mais alto que as demais camadas).\n",
        "\n",
        "Por fim, é um [fato conhecido](https://arxiv.org/pdf/1602.01517.pdf) que as redes neurais conseguem aprender características de baixo nível nas camadas iniciais. Geralmente, essas características são comuns à vários datasets. Por isso, uma opção durante o processo de *fine-tuning* é \"congelar\" as camadas iniciais (ou seja, não treiná-las) e treinar somente as demais camadas com taxa de aprendizado bem pequeno (exceto pela camada de classificação).\n",
        "\n",
        "No bloco de código abaixo, importamos a rede pré-treinada [AlexNet](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf), que foi treinada no dataset do [ImageNet](http://www.image-net.org/), que tem 1000 classes. Como iremos fazer *fine-tuning* nessa arquitetura para o dataset do [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html), que tem somente 10 classes, removeremos a última camada e criaremos uma nova camada inicializada aleatoriamente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hDGgIDhdG2z",
        "outputId": "61777eec-bff0-4563-e931-f0e9a101b357"
      },
      "source": [
        "# rede baseada na AlexNet \n",
        "net = torchvision.models.alexnet(pretrained=True)\n",
        "\n",
        "# Sending model to device\n",
        "net.to(device)\n",
        "\n",
        "print(summary(net,(3,227,227))) # visualize number of parameters' net, output of each layer and total mega bytes necessary for forward pass\n",
        "                                # and stored weights. \n",
        "\n",
        "num_ftrs = net.classifier[6].in_features\n",
        "net.classifier[6] = nn.Linear(num_ftrs,10) # Alterando a última layer para retornar 10 classes ao invés de 1000\n",
        "\n",
        "# Sending model to device\n",
        "net.to(device)\n",
        "\n",
        "# Verifique no output a última camada do classifier, podemos ver que sua saída é 10\n",
        "print(net)\n",
        "\n",
        "# Podemos ver que este output mostra que apenas  40970 parâmetros serão treinados. Ou seja, somente a última camada\n",
        "print(summary(net,(3,227,227))) \n",
        "\n",
        "# Treinando a última camada da rede acima\n",
        "# parâmetros: número de epochs, learning rate (ou taxa de aprendizado), \n",
        "# tamanho do batch, e lambda do weight decay\n",
        "num_epochs, lr, batch_size, wd_lambda = 20, 0.001, 100, 0.0001\n",
        "\n",
        "\n",
        "# função de custo (ou loss)\n",
        "loss = nn.CrossEntropyLoss()\n",
        "\n",
        "# carregamento do dado: cifar 10\n",
        "train_iter, test_iter = load_data_cifar10(batch_size, resize=227)\n",
        "\n",
        "# trainer\n",
        "trainer = optim.SGD([\n",
        "                {'params': net.features.parameters(), 'lr': lr * 0.1},\n",
        "                {'params': net.classifier[0:6].parameters(), 'lr': lr * 0.1},\n",
        "                {'params': net.classifier[6].parameters(), 'lr': lr}], weight_decay=wd_lambda, momentum=0.9)\n",
        "\n",
        "# treinamento e validação via Pytorch\n",
        "train_validate(net, train_iter, test_iter, batch_size, trainer, loss, \n",
        "                num_epochs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 56, 56]          23,296\n",
            "              ReLU-2           [-1, 64, 56, 56]               0\n",
            "         MaxPool2d-3           [-1, 64, 27, 27]               0\n",
            "            Conv2d-4          [-1, 192, 27, 27]         307,392\n",
            "              ReLU-5          [-1, 192, 27, 27]               0\n",
            "         MaxPool2d-6          [-1, 192, 13, 13]               0\n",
            "            Conv2d-7          [-1, 384, 13, 13]         663,936\n",
            "              ReLU-8          [-1, 384, 13, 13]               0\n",
            "            Conv2d-9          [-1, 256, 13, 13]         884,992\n",
            "             ReLU-10          [-1, 256, 13, 13]               0\n",
            "           Conv2d-11          [-1, 256, 13, 13]         590,080\n",
            "             ReLU-12          [-1, 256, 13, 13]               0\n",
            "        MaxPool2d-13            [-1, 256, 6, 6]               0\n",
            "AdaptiveAvgPool2d-14            [-1, 256, 6, 6]               0\n",
            "          Dropout-15                 [-1, 9216]               0\n",
            "           Linear-16                 [-1, 4096]      37,752,832\n",
            "             ReLU-17                 [-1, 4096]               0\n",
            "          Dropout-18                 [-1, 4096]               0\n",
            "           Linear-19                 [-1, 4096]      16,781,312\n",
            "             ReLU-20                 [-1, 4096]               0\n",
            "           Linear-21                 [-1, 1000]       4,097,000\n",
            "================================================================\n",
            "Total params: 61,100,840\n",
            "Trainable params: 61,100,840\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.59\n",
            "Forward/backward pass size (MB): 8.49\n",
            "Params size (MB): 233.08\n",
            "Estimated Total Size (MB): 242.16\n",
            "----------------------------------------------------------------\n",
            "None\n",
            "AlexNet(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): ReLU(inplace=True)\n",
            "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
            "  (classifier): Sequential(\n",
            "    (0): Dropout(p=0.5, inplace=False)\n",
            "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Dropout(p=0.5, inplace=False)\n",
            "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 56, 56]          23,296\n",
            "              ReLU-2           [-1, 64, 56, 56]               0\n",
            "         MaxPool2d-3           [-1, 64, 27, 27]               0\n",
            "            Conv2d-4          [-1, 192, 27, 27]         307,392\n",
            "              ReLU-5          [-1, 192, 27, 27]               0\n",
            "         MaxPool2d-6          [-1, 192, 13, 13]               0\n",
            "            Conv2d-7          [-1, 384, 13, 13]         663,936\n",
            "              ReLU-8          [-1, 384, 13, 13]               0\n",
            "            Conv2d-9          [-1, 256, 13, 13]         884,992\n",
            "             ReLU-10          [-1, 256, 13, 13]               0\n",
            "           Conv2d-11          [-1, 256, 13, 13]         590,080\n",
            "             ReLU-12          [-1, 256, 13, 13]               0\n",
            "        MaxPool2d-13            [-1, 256, 6, 6]               0\n",
            "AdaptiveAvgPool2d-14            [-1, 256, 6, 6]               0\n",
            "          Dropout-15                 [-1, 9216]               0\n",
            "           Linear-16                 [-1, 4096]      37,752,832\n",
            "             ReLU-17                 [-1, 4096]               0\n",
            "          Dropout-18                 [-1, 4096]               0\n",
            "           Linear-19                 [-1, 4096]      16,781,312\n",
            "             ReLU-20                 [-1, 4096]               0\n",
            "           Linear-21                   [-1, 10]          40,970\n",
            "================================================================\n",
            "Total params: 57,044,810\n",
            "Trainable params: 57,044,810\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.59\n",
            "Forward/backward pass size (MB): 8.48\n",
            "Params size (MB): 217.61\n",
            "Estimated Total Size (MB): 226.68\n",
            "----------------------------------------------------------------\n",
            "None\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "training on cuda\n",
            "epoch 1, train loss 0.9806, train acc 0.654, test loss 0.6364, test acc 0.776, time 84.2 sec\n",
            "epoch 2, train loss 0.6690, train acc 0.768, test loss 0.5465, test acc 0.809, time 84.4 sec\n",
            "epoch 3, train loss 0.5880, train acc 0.794, test loss 0.5182, test acc 0.818, time 84.2 sec\n",
            "epoch 4, train loss 0.5356, train acc 0.815, test loss 0.4531, test acc 0.844, time 84.3 sec\n",
            "epoch 5, train loss 0.5001, train acc 0.827, test loss 0.4471, test acc 0.847, time 84.5 sec\n",
            "epoch 6, train loss 0.4728, train acc 0.834, test loss 0.4193, test acc 0.855, time 84.3 sec\n",
            "epoch 7, train loss 0.4471, train acc 0.845, test loss 0.3970, test acc 0.860, time 84.6 sec\n",
            "epoch 8, train loss 0.4314, train acc 0.849, test loss 0.4118, test acc 0.856, time 84.6 sec\n",
            "epoch 9, train loss 0.4126, train acc 0.854, test loss 0.3848, test acc 0.864, time 84.8 sec\n",
            "epoch 10, train loss 0.3979, train acc 0.861, test loss 0.3758, test acc 0.870, time 84.8 sec\n",
            "epoch 11, train loss 0.3882, train acc 0.864, test loss 0.3794, test acc 0.866, time 84.6 sec\n",
            "epoch 12, train loss 0.3738, train acc 0.868, test loss 0.3636, test acc 0.870, time 84.4 sec\n",
            "epoch 13, train loss 0.3635, train acc 0.873, test loss 0.3448, test acc 0.877, time 84.7 sec\n",
            "epoch 14, train loss 0.3552, train acc 0.876, test loss 0.3551, test acc 0.874, time 84.1 sec\n",
            "epoch 15, train loss 0.3435, train acc 0.879, test loss 0.3383, test acc 0.881, time 84.4 sec\n",
            "epoch 16, train loss 0.3370, train acc 0.882, test loss 0.3313, test acc 0.885, time 84.0 sec\n",
            "epoch 17, train loss 0.3267, train acc 0.887, test loss 0.3287, test acc 0.883, time 83.9 sec\n",
            "epoch 18, train loss 0.3179, train acc 0.890, test loss 0.3288, test acc 0.883, time 83.9 sec\n",
            "epoch 19, train loss 0.3146, train acc 0.891, test loss 0.3229, test acc 0.887, time 83.9 sec\n",
            "epoch 20, train loss 0.3056, train acc 0.893, test loss 0.3206, test acc 0.886, time 83.9 sec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_uFa_Msi-EP"
      },
      "source": [
        "## Prática\n",
        "\n",
        "1. É possível melhorar o resultado obtido anteriormente?\n",
        "Estude o [model_zoo](https://pytorch.org/docs/stable/torchvision/models.html)  e tente usar as estratégias anteriores com diferentes redes neurais para melhorar o resultado.\n",
        "Algumas redes possíveis:\n",
        "\n",
        "- [MobileNets](https://arxiv.org/abs/1801.04381)\n",
        "- [VGGs](https://arxiv.org/abs/1409.1556)\n",
        "- [ResNets](https://arxiv.org/abs/1603.05027)\n",
        "- [DenseNets](https://arxiv.org/pdf/1608.06993.pdf)\n",
        "\n",
        "2. Procure agora congelar algumas camadas para realizar o *fine-tuning*. Essa estratégia é melhor quando se tem poucas imagens para fazer o *fine-tuning*.\n",
        "\n",
        "3. Procura usar outros algoritmos de aprendizado de máquina (como [*random forest*](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) e [SVM-RBF](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)) para classificar *deep features* extraídas de uma rede neural pré-treinada.\n",
        "  1. Procure também extrair e classificar *features* de outras camadas convolucionais.\n",
        "\n",
        "4. Procure usar as diferentes estratégias para melhorar os resultados dos datasets que já usamos, como [MNIST](https://pytorch.org/docs/stable/torchvision/datasets.html#torchvision.datasets.MNIST) e [Fashion MNIST](https://pytorch.org/docs/stable/torchvision/datasets.html#torchvision.datasets.FashionMNIST)."
      ]
    }
  ]
}